<html>
<head>
<meta charset="utf-8">
<title>/Users/malinda/Documents/RectrofitinMLtoCode/Python/TensorflowEx/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py</title>
<style type='text/css'>
body { color: #666666; }
a {
    text-decoration: none; color: #5AA2A7;
    border: solid 1px rgba(255,255,255,0);
}
a.active {
    background: -webkit-linear-gradient(top,rgba(255, 255, 200, 0.35) 0,rgba(255, 255, 200, 0.55) 100%);
    border: solid 1px #E5E600;
}
table, th, td { border: 1px solid lightgrey; padding: 5px; corner: rounded; }
.builtin {color: #B17E41;}
.comment, .block-comment {color: #aaaaaa; font-style: italic;}
.constant {color: #888888;}
.decorator {color: #778899;}
.doc-string {color: #aaaaaa;}
.error {border-bottom: 1px solid red;}
.field-name {color: #2e8b57;}
.function {color: #4682b4;}
.identifier {color: #8b7765;}
.info {border-bottom: 1px dotted RoyalBlue;}
.keyword {color: #0000cd;}
.lineno {color: #cccccc;}
.number {color: #483d8b;}
.parameter {color: #777777;}
.string {color: #999999;}
.type-name {color: #4682b4;}
.warning {border-bottom: 1px solid orange; padding-bottom: 1px}
</style>
<script language="JavaScript" type="text/javascript">
var highlighted;

function highlight(xid)
{
    var elms = document.querySelectorAll('[xid="' + xid + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "active";
    }
    highlighted = xid;
}

function clearHighlight() {
    var elms = document.querySelectorAll('[xid="' + highlighted + '"]');
    for (k in elms) {
        v = elms[k]
        v.className = "";
    }
}

window.onload =
    function (e) {
        var tags = document.getElementsByTagName("A")
        for (var i = 0; i < tags.length; i++) {
            tags[i].onmouseover =
                function (e) {
                    clearHighlight();
                    var xid = e.toElement.getAttribute('xid');
                    highlight(xid);
                }
        }
    }</script>
</head>
<body>
<table width=100% border='1px solid gray'><tr><td valign='top'><ul>
<li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.__all__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.__all__'>__all__</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._zero_state_tensors', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._zero_state_tensors'>_zero_state_tensors</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism'>AttentionMechanism</a><ul>
<li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.alignments_size', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.alignments_size'>alignments_size</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.state_size', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.state_size'>state_size</a></li></ul>
</li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory'>_prepare_memory</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score'>_maybe_mask_score</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism'>_BaseAttentionMechanism</a><ul>
<li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__'>__init__</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer'>memory_layer</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer'>query_layer</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.values', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.values'>values</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.keys', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.keys'>keys</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.batch_size', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.batch_size'>batch_size</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.alignments_size', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.alignments_size'>alignments_size</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.state_size', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.state_size'>state_size</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments'>initial_alignments</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state'>initial_state</a></li></ul>
</li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score'>_luong_score</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention'>LuongAttention</a><ul>
<li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__'>__init__</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__'>__call__</a></li></ul>
</li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score'>_bahdanau_score</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention'>BahdanauAttention</a><ul>
<li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__'>__init__</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__'>__call__</a></li></ul>
</li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod'>safe_cumprod</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention'>monotonic_attention</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn'>_monotonic_probability_fn</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism'>_BaseMonotonicAttentionMechanism</a><ul>
<li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments'>initial_alignments</a></li></ul>
</li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention'>BahdanauMonotonicAttention</a><ul>
<li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__'>__init__</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__'>__call__</a></li></ul>
</li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention'>LuongMonotonicAttention</a><ul>
<li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__'>__init__</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__'>__call__</a></li></ul>
</li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState'>AttentionWrapperState</a><ul>
<li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone'>clone</a></li></ul>
</li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax'>hardmax</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention'>_compute_attention</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper'>AttentionWrapper</a><ul>
<li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__'>__init__</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks'>_batch_size_checks</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple'>_item_or_tuple</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size'>output_size</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size'>state_size</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state'>zero_state</a></li><li><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call', xid='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call'>call</a></li></ul>
</li></ul>
</td><td><pre><span class='lineno'>   1</span> # Copyright 2017 The TensorFlow Authors. All Rights Reserved.
<span class='lineno'>   2</span> #
<span class='lineno'>   3</span> # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
<span class='lineno'>   4</span> # you may not use this file except in compliance with the License.
<span class='lineno'>   5</span> # You may obtain a copy of the License at
<span class='lineno'>   6</span> #
<span class='lineno'>   7</span> #     http://www.apache.org/licenses/LICENSE-2.0
<span class='lineno'>   8</span> #
<span class='lineno'>   9</span> # Unless required by applicable law or agreed to in writing, software
<span class='lineno'>  10</span> # distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
<span class='lineno'>  11</span> # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
<span class='lineno'>  12</span> # See the License for the specific language governing permissions and
<span class='lineno'>  13</span> # limitations under the License.
<span class='lineno'>  14</span> # ==============================================================================
<span class='lineno'>  15</span> &quot;&quot;&quot;A powerful dynamic attention wrapper object.&quot;&quot;&quot;
<span class='lineno'>  16</span> 
<span class='lineno'>  17</span> from __future__ import absolute_import
<span class='lineno'>  18</span> from __future__ import division
<span class='lineno'>  19</span> from __future__ import print_function
<span class='lineno'>  20</span> 
<span class='lineno'>  21</span> import collections
<span class='lineno'>  22</span> import functools
<span class='lineno'>  23</span> import math
<span class='lineno'>  24</span> 
<span class='lineno'>  25</span> import numpy as np
<span class='lineno'>  26</span> 
<span class='lineno'>  27</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib', title='contrib'>contrib</a>.<a href='../../../framework/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework', title='framework'>framework</a>.<a href='../../../framework/python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework.python', title='python'>python</a>.<a href='../../../framework/python/framework/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework.python.framework', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework.python.framework', title='framework'>framework</a> import <a href='../../../framework/python/framework/tensor_util.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework.python.framework.tensor_util', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework.python.framework.tensor_util', title='tensor_util'>tensor_util</a>
<span class='lineno'>  28</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/framework/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework', title='framework'>framework</a> import <a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', title='dtypes'>dtypes</a>
<span class='lineno'>  29</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/framework/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework', title='framework'>framework</a> import <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>
<span class='lineno'>  30</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/framework/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework', title='framework'>framework</a> import <a href='../../../../python/framework/tensor_shape.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.tensor_shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.tensor_shape', title='tensor_shape'>tensor_shape</a>
<span class='lineno'>  31</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/layers/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers', title='layers'>layers</a> import base as <a href='../../../../python/layers/base.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.base', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.base', title='base'>layers_base</a>
<span class='lineno'>  32</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/layers/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers', title='layers'>layers</a> import core as <a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', title='core'>layers_core</a>
<span class='lineno'>  33</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>
<span class='lineno'>  34</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/check_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops', title='check_ops'>check_ops</a>
<span class='lineno'>  35</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/clip_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.clip_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.clip_ops', title='clip_ops'>clip_ops</a>
<span class='lineno'>  36</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/functional_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.functional_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.functional_ops', title='functional_ops'>functional_ops</a>
<span class='lineno'>  37</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/init_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops', title='init_ops'>init_ops</a>
<span class='lineno'>  38</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>
<span class='lineno'>  39</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/nn_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.nn_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.nn_ops', title='nn_ops'>nn_ops</a>
<span class='lineno'>  40</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/random_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.random_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.random_ops', title='random_ops'>random_ops</a>
<span class='lineno'>  41</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/rnn_cell_impl.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl', title='rnn_cell_impl'>rnn_cell_impl</a>
<span class='lineno'>  42</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/tensor_array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.tensor_array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.tensor_array_ops', title='tensor_array_ops'>tensor_array_ops</a>
<span class='lineno'>  43</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/ops/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops', title='ops'>ops</a> import <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>
<span class='lineno'>  44</span> from <a href='../../../../__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow', title='tensorflow'>tensorflow</a>.<a href='../../../../python/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python', title='python'>python</a>.<a href='../../../../python/util/__init__.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util', title='util'>util</a> import <a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>
<span class='lineno'>  45</span> 
<span class='lineno'>  46</span> 
<span class='lineno'>  47</span> <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.__all__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.__all__', title='[str]'>__all__</a> = [
<span class='lineno'>  48</span>     &quot;AttentionMechanism&quot;,
<span class='lineno'>  49</span>     &quot;AttentionWrapper&quot;,
<span class='lineno'>  50</span>     &quot;AttentionWrapperState&quot;,
<span class='lineno'>  51</span>     &quot;LuongAttention&quot;,
<span class='lineno'>  52</span>     &quot;BahdanauAttention&quot;,
<span class='lineno'>  53</span>     &quot;hardmax&quot;,
<span class='lineno'>  54</span>     &quot;safe_cumprod&quot;,
<span class='lineno'>  55</span>     &quot;monotonic_attention&quot;,
<span class='lineno'>  56</span>     &quot;BahdanauMonotonicAttention&quot;,
<span class='lineno'>  57</span>     &quot;LuongMonotonicAttention&quot;,
<span class='lineno'>  58</span> ]
<span class='lineno'>  59</span> 
<span class='lineno'>  60</span> 
<span class='lineno'>  61</span> <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._zero_state_tensors', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._zero_state_tensors', title='(CrfDecodeForwardRnnCell -> ?, None, None) -> ? / (CrfForwardRnnCell -> ?, None, None) -> None / (int, ?, ?) -> None / (_RNNCellForTest -> ?, None, None) -> None / (LSTMCell -> {LSTMStateTuple | int}, int, ?) -> None / (?, ?, ?) -> None / (RNNCell -> None, None, None) -> None / (RNNCell -> None, ?, ?) -> None'>_zero_state_tensors</a> = <a href='../../../../python/ops/rnn_cell_impl.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl', title='rnn_cell_impl'>rnn_cell_impl</a>.<a href='../../../../python/ops/rnn_cell_impl.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl._zero_state_tensors', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl._zero_state_tensors', title='(CrfDecodeForwardRnnCell -> ?, None, None) -> ? / (CrfForwardRnnCell -> ?, None, None) -> None / (int, ?, ?) -> None / (_RNNCellForTest -> ?, None, None) -> None / (LSTMCell -> {LSTMStateTuple | int}, int, ?) -> None / (?, ?, ?) -> None / (RNNCell -> None, None, None) -> None / (RNNCell -> None, ?, ?) -> None'>_zero_state_tensors</a>  # pylint: disable=protected-access
<span class='lineno'>  62</span> 
<span class='lineno'>  63</span> 
<span class='lineno'>  64</span> class <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism', title='<AttentionMechanism>'>AttentionMechanism</a>(object):
<span class='lineno'>  65</span> 
<span class='lineno'>  66</span>   @property
<span class='lineno'>  67</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.alignments_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.alignments_size', title='AttentionMechanism -> None'>alignments_size</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.alignments_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.alignments_size.self', title='AttentionMechanism'>self</a>):
<span class='lineno'>  68</span>     raise NotImplementedError
<span class='lineno'>  69</span> 
<span class='lineno'>  70</span>   @property
<span class='lineno'>  71</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.state_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.state_size', title='AttentionMechanism -> None'>state_size</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism.state_size.self', title='AttentionMechanism'>self</a>):
<span class='lineno'>  72</span>     raise NotImplementedError
<span class='lineno'>  73</span> 
<span class='lineno'>  74</span> 
<span class='lineno'>  75</span> def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory', title='(?, ?, ?) -> None / (?, None, bool) -> None'>_prepare_memory</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', title='?'>memory</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', title='None'>memory_sequence_length</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.check_inner_dims_defined', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.check_inner_dims_defined', title='bool'>check_inner_dims_defined</a>):
<span class='lineno'>  76</span>   &quot;&quot;&quot;Convert to tensor and possibly mask `memory`.
<span class='lineno'>  77</span> 
<span class='lineno'>  78</span>   Args:
<span class='lineno'>  79</span>     memory: `Tensor`, shaped `[batch_size, max_time, ...]`.
<span class='lineno'>  80</span>     memory_sequence_length: `int32` `Tensor`, shaped `[batch_size]`.
<span class='lineno'>  81</span>     check_inner_dims_defined: Python boolean.  If `True`, the `memory`
<span class='lineno'>  82</span>       argument&#39;s shape is checked to ensure all but the two outermost
<span class='lineno'>  83</span>       dimensions are fully defined.
<span class='lineno'>  84</span> 
<span class='lineno'>  85</span>   Returns:
<span class='lineno'>  86</span>     A (possibly masked), checked, new `memory`.
<span class='lineno'>  87</span> 
<span class='lineno'>  88</span>   Raises:
<span class='lineno'>  89</span>     ValueError: If `check_inner_dims_defined` is `True` and not
<span class='lineno'>  90</span>       `memory.shape[2:].is_fully_defined()`.
<span class='lineno'>  91</span>   &quot;&quot;&quot;
<span class='lineno'>  92</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', title='?'>memory</a> = <a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>.<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', title='? -> ? -> ? / ? -> ? -> None / ? -> TensorArray -> None / ? -> None / list -> list -> None / ? -> _DotString -> _DotString / (_TensorLike, None) -> ? / (IndexedSlices -> None, None) -> None / (None, None) -> None / ({IndexedSlices | SparseTensor}, None) -> None / (?, None) -> None / ({None | [None]}, None) -> None / ({? -> bool | None}, None) -> None / (Tensor, None) -> None -> None / (CondContext, ?) -> {IndexedSlices | SparseTensor | list} -> {IndexedSlices | SparseTensor | list} / ? -> TensorArray -> None -> TensorArray -> None'>map_structure</a>(
<span class='lineno'>  93</span>       lambda <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.lambda%652.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.lambda%652.m', title='?'>m</a>: <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', title='(SparseTensor -> None, None, None, None) -> ? / (SparseTensor -> None, None, None, None) -> None / ({None | int}, None, None, None) -> None / (int, None, None, None) -> None / (?, None, None, None) -> None / (None, DType, None, None) -> None / (?, DType, None, None) -> None / (None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / ({IndexedSlices | SparseTensor}, DType, None, None) -> None'>convert_to_tensor</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.lambda%652.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.lambda%652.m', title='?'>m</a>, name=&quot;memory&quot;), <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', title='?'>memory</a>)
<span class='lineno'>  94</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', title='None'>memory_sequence_length</a> is not None:
<span class='lineno'>  95</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', title='None'>memory_sequence_length</a> = <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', title='(SparseTensor -> None, None, None, None) -> ? / (SparseTensor -> None, None, None, None) -> None / ({None | int}, None, None, None) -> None / (int, None, None, None) -> None / (?, None, None, None) -> None / (None, DType, None, None) -> None / (?, DType, None, None) -> None / (None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / ({IndexedSlices | SparseTensor}, DType, None, None) -> None'>convert_to_tensor</a>(
<span class='lineno'>  96</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', title='None'>memory_sequence_length</a>, name=&quot;memory_sequence_length&quot;)
<span class='lineno'>  97</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.check_inner_dims_defined', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.check_inner_dims_defined', title='bool'>check_inner_dims_defined</a>:
<span class='lineno'>  98</span>     def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._check_dims', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._check_dims', title='? -> None'>_check_dims</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._check_dims.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._check_dims.m', title='?'>m</a>):
<span class='lineno'>  99</span>       if not <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._check_dims.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._check_dims.m', title='?'>m</a>.get_shape()[2:].is_fully_defined():
<span class='lineno'> 100</span>         raise ValueError(&quot;Expected memory %s to have fully defined inner dims, &quot;
<span class='lineno'> 101</span>                          &quot;but saw shape: %s&quot; % (m.name, m.get_shape()))
<span class='lineno'> 102</span>     <a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>.<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', title='? -> ? -> ? / ? -> ? -> None / ? -> TensorArray -> None / ? -> None / list -> list -> None / ? -> _DotString -> _DotString / (_TensorLike, None) -> ? / (IndexedSlices -> None, None) -> None / (None, None) -> None / ({IndexedSlices | SparseTensor}, None) -> None / (?, None) -> None / ({None | [None]}, None) -> None / ({? -> bool | None}, None) -> None / (Tensor, None) -> None -> None / (CondContext, ?) -> {IndexedSlices | SparseTensor | list} -> {IndexedSlices | SparseTensor | list} / ? -> TensorArray -> None -> TensorArray -> None'>map_structure</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._check_dims', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._check_dims', title='? -> None'>_check_dims</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', title='?'>memory</a>)
<span class='lineno'> 103</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', title='None'>memory_sequence_length</a> is None:
<span class='lineno'> 104</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.seq_len_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.seq_len_mask', title='None'>seq_len_mask</a> = None
<span class='lineno'> 105</span>   else:
<span class='lineno'> 106</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.seq_len_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.seq_len_mask', title='bool'>seq_len_mask</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.sequence_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.sequence_mask', title='(None, None, DType, None) -> bool / (None, ?, DType, None) -> bool / (?, None, DType, None) -> bool / (?, ?, DType, None) -> bool'>sequence_mask</a>(
<span class='lineno'> 107</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', title='None'>memory_sequence_length</a>,
<span class='lineno'> 108</span>         maxlen=<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>.<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.flatten', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.flatten', title='{? -> list | EagerIterator | Iterator | None | [?] | [None] | [None] | dict} -> ? / {(? -> list, ? -> tuple) | ? -> list | EagerIterator | Iterator | dict} -> None / {? -> list | dict} -> None / [?] -> None / {IndexedSlices | SparseTensor | [{IndexedSlices | SparseTensor | list}] | list} -> None / ? -> None / None -> None / {(? -> list, ? -> tuple) | EagerIterator | Iterator | dict} -> None / [tuple] -> None'>flatten</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', title='?'>memory</a>)[0])[1],
<span class='lineno'> 109</span>         dtype=<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>.<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.flatten', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.flatten', title='{? -> list | EagerIterator | Iterator | None | [?] | [None] | [None] | dict} -> ? / {(? -> list, ? -> tuple) | ? -> list | EagerIterator | Iterator | dict} -> None / {? -> list | dict} -> None / [?] -> None / {IndexedSlices | SparseTensor | [{IndexedSlices | SparseTensor | list}] | list} -> None / ? -> None / None -> None / {(? -> list, ? -> tuple) | EagerIterator | Iterator | dict} -> None / [tuple] -> None'>flatten</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', title='?'>memory</a>)[0].dtype)
<span class='lineno'> 110</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.seq_len_batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.seq_len_batch_size', title='?'>seq_len_batch_size</a> = (
<span class='lineno'> 111</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', title='None'>memory_sequence_length</a>.shape[0].value
<span class='lineno'> 112</span>         or <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', title='None'>memory_sequence_length</a>)[0])
<span class='lineno'> 113</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask', title='(?, ?) -> None / (?, bool) -> None'>_maybe_mask</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', title='?'>m</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.seq_len_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.seq_len_mask', title='bool'>seq_len_mask</a>):
<span class='lineno'> 114</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.rank', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.rank', title='?'>rank</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', title='?'>m</a>.get_shape().ndims
<span class='lineno'> 115</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.rank', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.rank', title='None'>rank</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.rank', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.rank', title='?'>rank</a> if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.rank', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.rank', title='?'>rank</a> is not None else <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.rank', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.rank', title='([?], None) -> ? / (None, None) -> None / (SparseTensor, None) -> None / (ExpRelaxedOneHotCategorical -> {IndexedSlices | SparseTensor}, None) -> None / ({IndexedSlices | SparseTensor}, None) -> None / (?, None) -> None / ({None | TensorArray | tuple}, None) -> None / ({int | list}, None) -> None / ((None, None), None) -> None'>rank</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', title='?'>m</a>)
<span class='lineno'> 116</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.extra_ones', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.extra_ones', title='?'>extra_ones</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.ones', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.ones', title='([None], ?, None) -> ? / ([?], ?, None) -> ? / ((?, int), DType, None) -> ? / (?, DType, None) -> ? / ([?], DType, None) -> ? / (None, DType, None) -> ? / ([None], DType, None) -> ? / ([int], DType, None) -> ? / (LinearOperator -> None, DType, None) -> ?'>ones</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.rank', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.rank', title='None'>rank</a> - 2, dtype=<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', title='dtypes'>dtypes</a>.<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.int32', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.int32', title='DType'>int32</a>)
<span class='lineno'> 117</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m_batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m_batch_size', title='?'>m_batch_size</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', title='?'>m</a>.shape[0].value or <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', title='?'>m</a>)[0]
<span class='lineno'> 118</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory_sequence_length', title='None'>memory_sequence_length</a> is not None:
<span class='lineno'> 119</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.message', title='str'>message</a> = (&quot;memory_sequence_length and memory tensor batch sizes do not &quot;
<span class='lineno'> 120</span>                  &quot;match.&quot;)
<span class='lineno'> 121</span>       with <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.control_dependencies', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.control_dependencies', title='? -> ? / {[?] | [None]} -> _NullContextmanager / None -> _NullContextmanager / list -> _NullContextmanager / [Operation] -> _NullContextmanager / [None] -> _NullContextmanager / ? -> _NullContextmanager / [?] -> _NullContextmanager / [{IndexedSlices -> None | SparseTensor -> None}] -> _NullContextmanager'>control_dependencies</a>([
<span class='lineno'> 122</span>           <a href='../../../../python/ops/check_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops', title='check_ops'>check_ops</a>.<a href='../../../../python/ops/check_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops.assert_equal', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops.assert_equal', title='({IndexedSlices | SparseTensor}, float, None, None, None, None) -> ? / (int, ?, None, None, None, None) -> None / (?, int, None, None, None, None) -> None / (?, bool, None, None, None, None) -> None / (None, bool, None, None, None, None) -> None / (None, ?, None, None, None, None) -> None / (?, ?, None, None, None, None) -> None / (?, None, None, None, None, None) -> None / (None, None, None, None, None, None) -> None'>assert_equal</a>(
<span class='lineno'> 123</span>               <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.seq_len_batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.seq_len_batch_size', title='?'>seq_len_batch_size</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m_batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m_batch_size', title='?'>m_batch_size</a>, message=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.message', title='str'>message</a>)]):
<span class='lineno'> 124</span>         <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.seq_len_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.seq_len_mask', title='?'>seq_len_mask</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/gen_array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.gen_array_ops.reshape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.gen_array_ops.reshape', title='({None | [None]}, [int], None) -> ? / ({[DeferredTensor] | [None]}, None, None) -> ? / (None, None, None) -> ? / (?, None, None) -> ? / (None, [int], None) -> ? / (?, [int], None) -> ? / (None, ?, None) -> ? / (None, [?], None) -> ?'>reshape</a>(
<span class='lineno'> 125</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.seq_len_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.seq_len_mask', title='bool'>seq_len_mask</a>,
<span class='lineno'> 126</span>             <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.concat', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.concat', title='((?, [?]), int, str) -> ? / ([[?]], int, str) -> None / ([?], int, str) -> None / ([{None | [int]}], int, str) -> None / ([IndexedSlices -> None], int, str) -> None / ([None], int, str) -> None / (?, int, str) -> None / ((None, None), int, str) -> None / ([{IndexedSlices | SparseTensor}], int, str) -> None'>concat</a>((<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.seq_len_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.seq_len_mask', title='bool'>seq_len_mask</a>), <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.extra_ones', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.extra_ones', title='?'>extra_ones</a>), 0))
<span class='lineno'> 127</span>         return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', title='?'>m</a> * <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.seq_len_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.seq_len_mask', title='?'>seq_len_mask</a>
<span class='lineno'> 128</span>     else:
<span class='lineno'> 129</span>       return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask.m', title='?'>m</a>
<span class='lineno'> 130</span>   return <a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>.<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', title='? -> ? -> ? / ? -> ? -> None / ? -> TensorArray -> None / ? -> None / list -> list -> None / ? -> _DotString -> _DotString / (_TensorLike, None) -> ? / (IndexedSlices -> None, None) -> None / (None, None) -> None / ({IndexedSlices | SparseTensor}, None) -> None / (?, None) -> None / ({None | [None]}, None) -> None / ({? -> bool | None}, None) -> None / (Tensor, None) -> None -> None / (CondContext, ?) -> {IndexedSlices | SparseTensor | list} -> {IndexedSlices | SparseTensor | list} / ? -> TensorArray -> None -> TensorArray -> None'>map_structure</a>(lambda <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.lambda%653.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.lambda%653.m', title='?'>m</a>: <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory._maybe_mask', title='(?, ?) -> None / (?, bool) -> None'>_maybe_mask</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.lambda%653.m', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.lambda%653.m', title='?'>m</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.seq_len_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.seq_len_mask', title='bool'>seq_len_mask</a>), <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory.memory', title='?'>memory</a>)
<span class='lineno'> 131</span> 
<span class='lineno'> 132</span> 
<span class='lineno'> 133</span> def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score', title='(?, None, None) -> None / (?, ?, ?) -> None'>_maybe_mask_score</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score', title='?'>score</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.memory_sequence_length', title='None'>memory_sequence_length</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask_value', title='None'>score_mask_value</a>):
<span class='lineno'> 134</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.memory_sequence_length', title='None'>memory_sequence_length</a> is None:
<span class='lineno'> 135</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score', title='?'>score</a>
<span class='lineno'> 136</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.message', title='str'>message</a> = (&quot;All values in memory_sequence_length must greater than zero.&quot;)
<span class='lineno'> 137</span>   with <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.control_dependencies', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.control_dependencies', title='? -> ? / {[?] | [None]} -> _NullContextmanager / None -> _NullContextmanager / list -> _NullContextmanager / [Operation] -> _NullContextmanager / [None] -> _NullContextmanager / ? -> _NullContextmanager / [?] -> _NullContextmanager / [{IndexedSlices -> None | SparseTensor -> None}] -> _NullContextmanager'>control_dependencies</a>(
<span class='lineno'> 138</span>       [<a href='../../../../python/ops/check_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops', title='check_ops'>check_ops</a>.<a href='../../../../python/ops/check_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops.assert_positive', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops.assert_positive', title='(LinearOperatorScaledIdentity -> None, None, None, None, None) -> ? / (float, None, None, None, None) -> None / (_BaseLinearOperatorCirculant -> None, None, None, None, None) -> None / (SparseTensor, None, None, None, None) -> None / (None, None, None, None, None) -> None / (?, None, None, None, None) -> None / (None, [str], None, None, None) -> None / ({IndexedSlices | None | SparseTensor}, None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None, None) -> None'>assert_positive</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.memory_sequence_length', title='None'>memory_sequence_length</a>, message=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.message', title='str'>message</a>)]):
<span class='lineno'> 139</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask', title='bool'>score_mask</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.sequence_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.sequence_mask', title='(None, None, DType, None) -> bool / (None, ?, DType, None) -> bool / (?, None, DType, None) -> bool / (?, ?, DType, None) -> bool'>sequence_mask</a>(
<span class='lineno'> 140</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.memory_sequence_length', title='None'>memory_sequence_length</a>, maxlen=<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score', title='?'>score</a>)[1])
<span class='lineno'> 141</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask_values', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask_values', title='None'>score_mask_values</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask_value', title='None'>score_mask_value</a> * <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.ones_like', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.ones_like', title='(?, ?, None, bool) -> ? / (Normal -> None, None, None, bool) -> None / (_Gumbel -> None, None, None, bool) -> None / (SparseTensor -> None, None, None, bool) -> None / (?, None, None, bool) -> None / (None, None, None, bool) -> None / ({IndexedSlices | SparseTensor}, None, None, bool) -> None / ({IndexedSlices | SparseTensor}, DType, None, bool) -> None / (Multinomial -> {IndexedSlices | SparseTensor}, None, None, bool) -> None / ([int], None, None, bool) -> None'>ones_like</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score', title='?'>score</a>)
<span class='lineno'> 142</span>     return <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.where', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.where', title='(bool, ?, None, None) -> ? / (?, ?, ?, None) -> None / (?, ?, None, None) -> None / (?, None, ?, None) -> None / (bool, SparseTensor, None, None) -> None / (bool, None, None, None) -> None / (bool, int, ?, None) -> None / (?, None, None, None) -> None'>where</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask', title='bool'>score_mask</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score', title='?'>score</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask_values', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score.score_mask_values', title='None'>score_mask_values</a>)
<span class='lineno'> 143</span> 
<span class='lineno'> 144</span> 
<span class='lineno'> 145</span> class <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism', title='<_BaseAttentionMechanism>'>_BaseAttentionMechanism</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism', title='<AttentionMechanism>'>AttentionMechanism</a>):
<span class='lineno'> 146</span>   &quot;&quot;&quot;A base AttentionMechanism class providing common functionality.
<span class='lineno'> 147</span> 
<span class='lineno'> 148</span>   Common functionality includes:
<span class='lineno'> 149</span>     1. Storing the query and memory layers.
<span class='lineno'> 150</span>     2. Preprocessing and storing the memory.
<span class='lineno'> 151</span>   &quot;&quot;&quot;
<span class='lineno'> 152</span> 
<span class='lineno'> 153</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__', title='? -> ?'>__init__</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>,
<span class='lineno'> 154</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.query_layer', title='?'>query_layer</a>,
<span class='lineno'> 155</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory', title='?'>memory</a>,
<span class='lineno'> 156</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.probability_fn', title='?'>probability_fn</a>,
<span class='lineno'> 157</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>=None,
<span class='lineno'> 158</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_layer', title='None'>memory_layer</a>=None,
<span class='lineno'> 159</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.check_inner_dims_defined', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.check_inner_dims_defined', title='bool'>check_inner_dims_defined</a>=True,
<span class='lineno'> 160</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.score_mask_value', title='None'>score_mask_value</a>=None,
<span class='lineno'> 161</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.name', title='None'>name</a>=None):
<span class='lineno'> 162</span>     &quot;&quot;&quot;Construct base AttentionMechanism class.
<span class='lineno'> 163</span> 
<span class='lineno'> 164</span>     Args:
<span class='lineno'> 165</span>       query_layer: Callable.  Instance of `tf.layers.Layer`.  The layer&#39;s depth
<span class='lineno'> 166</span>         must match the depth of `memory_layer`.  If `query_layer` is not
<span class='lineno'> 167</span>         provided, the shape of `query` must match that of `memory_layer`.
<span class='lineno'> 168</span>       memory: The memory to query; usually the output of an RNN encoder.  This
<span class='lineno'> 169</span>         tensor should be shaped `[batch_size, max_time, ...]`.
<span class='lineno'> 170</span>       probability_fn: A `callable`.  Converts the score and previous alignments
<span class='lineno'> 171</span>         to probabilities. Its signature should be:
<span class='lineno'> 172</span>         `probabilities = probability_fn(score, state)`.
<span class='lineno'> 173</span>       memory_sequence_length (optional): Sequence lengths for the batch entries
<span class='lineno'> 174</span>         in memory.  If provided, the memory tensor rows are masked with zeros
<span class='lineno'> 175</span>         for values past the respective sequence lengths.
<span class='lineno'> 176</span>       memory_layer: Instance of `tf.layers.Layer` (may be None).  The layer&#39;s
<span class='lineno'> 177</span>         depth must match the depth of `query_layer`.
<span class='lineno'> 178</span>         If `memory_layer` is not provided, the shape of `memory` must match
<span class='lineno'> 179</span>         that of `query_layer`.
<span class='lineno'> 180</span>       check_inner_dims_defined: Python boolean.  If `True`, the `memory`
<span class='lineno'> 181</span>         argument&#39;s shape is checked to ensure all but the two outermost
<span class='lineno'> 182</span>         dimensions are fully defined.
<span class='lineno'> 183</span>       score_mask_value: (optional): The mask value for score before passing into
<span class='lineno'> 184</span>         `probability_fn`. The default is -inf. Only used if
<span class='lineno'> 185</span>         `memory_sequence_length` is not None.
<span class='lineno'> 186</span>       name: Name to use when creating ops.
<span class='lineno'> 187</span>     &quot;&quot;&quot;
<span class='lineno'> 188</span>     if (<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.query_layer', title='?'>query_layer</a> is not None
<span class='lineno'> 189</span>         and not isinstance(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.query_layer', title='?'>query_layer</a>, <a href='../../../../python/layers/base.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.base', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.base', title='base'>layers_base</a>.<a href='../../../../python/layers/base.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.base.Layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.base.Layer', title='<Layer>'>Layer</a>)):
<span class='lineno'> 190</span>       raise TypeError(
<span class='lineno'> 191</span>           &quot;query_layer is not a Layer: %s&quot; % type(query_layer).__name__)
<span class='lineno'> 192</span>     if (<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_layer', title='None'>memory_layer</a> is not None
<span class='lineno'> 193</span>         and not isinstance(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_layer', title='None'>memory_layer</a>, <a href='../../../../python/layers/base.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.base', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.base', title='base'>layers_base</a>.<a href='../../../../python/layers/base.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.base.Layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.base.Layer', title='<Layer>'>Layer</a>)):
<span class='lineno'> 194</span>       raise TypeError(
<span class='lineno'> 195</span>           &quot;memory_layer is not a Layer: %s&quot; % type(memory_layer).__name__)
<span class='lineno'> 196</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._query_layer', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._query_layer', title='?'>_query_layer</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.query_layer', title='?'>query_layer</a>
<span class='lineno'> 197</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._memory_layer', title='None'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._memory_layer', title='None'>_memory_layer</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_layer', title='None'>memory_layer</a>
<span class='lineno'> 198</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.dtype', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.dtype', title='?'>dtype</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_layer', title='None'>memory_layer</a>.dtype
<span class='lineno'> 199</span>     if not callable(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.probability_fn', title='?'>probability_fn</a>):
<span class='lineno'> 200</span>       raise TypeError(&quot;probability_fn must be callable, saw type: %s&quot; %
<span class='lineno'> 201</span>                       type(probability_fn).__name__)
<span class='lineno'> 202</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.score_mask_value', title='None'>score_mask_value</a> is None:
<span class='lineno'> 203</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.score_mask_value', title='None'>score_mask_value</a> = <a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', title='dtypes'>dtypes</a>.<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.as_dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.as_dtype', title='SparseTensor -> None -> ? / {IndexedSlices -> None | SparseTensor -> None} -> DType / DType -> DType -> DType / int -> DType / ? -> DType / DType -> DType / None -> DType / Tensor -> DType -> DType / {DType | Tensor -> DType | [?] | int} -> DType / {DType | [?] | int} -> DType'>as_dtype</a>(
<span class='lineno'> 204</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._memory_layer', title='None'>_memory_layer</a>.dtype).<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.DType.as_numpy_dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.DType.as_numpy_dtype', title='DType -> None'>as_numpy_dtype</a>(-np.inf)
<span class='lineno'> 205</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._probability_fn', title='(?, ?) -> ?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._probability_fn', title='(?, ?) -> ?'>_probability_fn</a></a> = lambda <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.lambda%654.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.lambda%654.score', title='?'>score</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.lambda%654.prev', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.lambda%654.prev', title='?'>prev</a>: (  # pylint:disable=g-long-lambda
<span class='lineno'> 206</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.probability_fn', title='?'>probability_fn</a>(
<span class='lineno'> 207</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._maybe_mask_score', title='(?, None, None) -> None / (?, ?, ?) -> None'>_maybe_mask_score</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.lambda%654.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.lambda%654.score', title='?'>score</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.score_mask_value', title='None'>score_mask_value</a>),
<span class='lineno'> 208</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.lambda%654.prev', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.lambda%654.prev', title='?'>prev</a>))
<span class='lineno'> 209</span>     with <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.name_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.name_scope', title='{(None, str, list) -> ? / (None, str, (?, ?, float)) -> {name_scope | variable_scope} / (None, str, [bool]) -> {name_scope | variable_scope} / (None, str, (?, ?, None)) -> {name_scope | variable_scope} / (None, str, [None]) -> {name_scope | variable_scope} / (None, str, [?]) -> {name_scope | variable_scope} / (str, None, None) -> {name_scope | variable_scope} / (None, str, ?) -> {name_scope | variable_scope} / (None, str, [{IndexedSlices | None | SparseTensor}]) -> {name_scope | variable_scope} | <name_scope>}'>name_scope</a>(
<span class='lineno'> 210</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.name', title='None'>name</a>, &quot;BaseAttentionMechanismInit&quot;, <a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>.<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.flatten', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.flatten', title='{? -> list | EagerIterator | Iterator | None | [?] | [None] | [None] | dict} -> ? / {(? -> list, ? -> tuple) | ? -> list | EagerIterator | Iterator | dict} -> None / {? -> list | dict} -> None / [?] -> None / {IndexedSlices | SparseTensor | [{IndexedSlices | SparseTensor | list}] | list} -> None / ? -> None / None -> None / {(? -> list, ? -> tuple) | EagerIterator | Iterator | dict} -> None / [tuple] -> None'>flatten</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory', title='?'>memory</a>)):
<span class='lineno'> 211</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._values', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._values', title='None'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._values', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._values', title='None'>_values</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._prepare_memory', title='(?, ?, ?) -> None / (?, None, bool) -> None'>_prepare_memory</a>(
<span class='lineno'> 212</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory', title='?'>memory</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>,
<span class='lineno'> 213</span>           check_inner_dims_defined=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.check_inner_dims_defined', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.check_inner_dims_defined', title='bool'>check_inner_dims_defined</a>)
<span class='lineno'> 214</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', title='None'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', title='None'>_keys</a></a> = (
<span class='lineno'> 215</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer', title='_BaseMonotonicAttentionMechanism -> None / _BaseAttentionMechanism -> None'>memory_layer</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._values', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._values', title='None'>_values</a>) if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer', title='_BaseMonotonicAttentionMechanism -> None / _BaseAttentionMechanism -> None'>memory_layer</a>  # pylint: disable=not-callable
<span class='lineno'> 216</span>           else <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._values', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._values', title='None'>_values</a>)
<span class='lineno'> 217</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._batch_size', title='?'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._batch_size', title='?'>_batch_size</a></a> = (
<span class='lineno'> 218</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', title='None'>_keys</a>.shape[0].value or <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', title='None'>_keys</a>)[0])
<span class='lineno'> 219</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._alignments_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._alignments_size', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._alignments_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._alignments_size', title='?'>_alignments_size</a></a> = (<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', title='None'>_keys</a>.shape[1].value or
<span class='lineno'> 220</span>                                <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.__init__.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', title='None'>_keys</a>)[1])
<span class='lineno'> 221</span> 
<span class='lineno'> 222</span>   @property
<span class='lineno'> 223</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer', title='_BaseMonotonicAttentionMechanism -> None / _BaseAttentionMechanism -> None'>memory_layer</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>):
<span class='lineno'> 224</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.memory_layer.self', title='{_BaseAttentionMechanism | _BaseMonotonicAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._memory_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._memory_layer', title='None'>_memory_layer</a>
<span class='lineno'> 225</span> 
<span class='lineno'> 226</span>   @property
<span class='lineno'> 227</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', title='BahdanauAttention -> ? / _BaseAttentionMechanism -> ? / BahdanauMonotonicAttention -> ?'>query_layer</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer.self', title='{BahdanauAttention | BahdanauMonotonicAttention | _BaseAttentionMechanism}'>self</a>):
<span class='lineno'> 228</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer.self', title='{BahdanauAttention | BahdanauMonotonicAttention | _BaseAttentionMechanism}'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._query_layer', title='?'>_query_layer</a>
<span class='lineno'> 229</span> 
<span class='lineno'> 230</span>   @property
<span class='lineno'> 231</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.values', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.values', title='_BaseAttentionMechanism -> None'>values</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.values.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.values.self', title='_BaseAttentionMechanism'>self</a>):
<span class='lineno'> 232</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.values.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.values.self', title='_BaseAttentionMechanism'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._values', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._values', title='None'>_values</a>
<span class='lineno'> 233</span> 
<span class='lineno'> 234</span>   @property
<span class='lineno'> 235</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.keys', title='_BaseAttentionMechanism -> None'>keys</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.keys.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.keys.self', title='_BaseAttentionMechanism'>self</a>):
<span class='lineno'> 236</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.keys.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.keys.self', title='_BaseAttentionMechanism'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._keys', title='None'>_keys</a>
<span class='lineno'> 237</span> 
<span class='lineno'> 238</span>   @property
<span class='lineno'> 239</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.batch_size', title='_BaseAttentionMechanism -> ?'>batch_size</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.batch_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.batch_size.self', title='_BaseAttentionMechanism'>self</a>):
<span class='lineno'> 240</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.batch_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.batch_size.self', title='_BaseAttentionMechanism'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._batch_size', title='?'>_batch_size</a>
<span class='lineno'> 241</span> 
<span class='lineno'> 242</span>   @property
<span class='lineno'> 243</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.alignments_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.alignments_size', title='_BaseAttentionMechanism -> ?'>alignments_size</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.alignments_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.alignments_size.self', title='_BaseAttentionMechanism'>self</a>):
<span class='lineno'> 244</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.alignments_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.alignments_size.self', title='_BaseAttentionMechanism'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._alignments_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._alignments_size', title='?'>_alignments_size</a>
<span class='lineno'> 245</span> 
<span class='lineno'> 246</span>   @property
<span class='lineno'> 247</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.state_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.state_size', title='_BaseAttentionMechanism -> ?'>state_size</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.state_size.self', title='_BaseAttentionMechanism'>self</a>):
<span class='lineno'> 248</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.state_size.self', title='_BaseAttentionMechanism'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._alignments_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._alignments_size', title='?'>_alignments_size</a>
<span class='lineno'> 249</span> 
<span class='lineno'> 250</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments', title='(_BaseAttentionMechanism, ?, ?) -> None'>initial_alignments</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.self', title='_BaseAttentionMechanism'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.batch_size', title='?'>batch_size</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.dtype', title='?'>dtype</a>):
<span class='lineno'> 251</span>     &quot;&quot;&quot;Creates the initial alignment values for the `AttentionWrapper` class.
<span class='lineno'> 252</span> 
<span class='lineno'> 253</span>     This is important for AttentionMechanisms that use the previous alignment
<span class='lineno'> 254</span>     to calculate the alignment at the next time step (e.g. monotonic attention).
<span class='lineno'> 255</span> 
<span class='lineno'> 256</span>     The default behavior is to return a tensor of all zeros.
<span class='lineno'> 257</span> 
<span class='lineno'> 258</span>     Args:
<span class='lineno'> 259</span>       batch_size: `int32` scalar, the batch_size.
<span class='lineno'> 260</span>       dtype: The `dtype`.
<span class='lineno'> 261</span> 
<span class='lineno'> 262</span>     Returns:
<span class='lineno'> 263</span>       A `dtype` tensor shaped `[batch_size, alignments_size]`
<span class='lineno'> 264</span>       (`alignments_size` is the values&#39; `max_time`).
<span class='lineno'> 265</span>     &quot;&quot;&quot;
<span class='lineno'> 266</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.max_time', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.max_time', title='?'>max_time</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.self', title='_BaseAttentionMechanism'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._alignments_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism._alignments_size', title='?'>_alignments_size</a>
<span class='lineno'> 267</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._zero_state_tensors', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._zero_state_tensors', title='(CrfDecodeForwardRnnCell -> ?, None, None) -> ? / (CrfForwardRnnCell -> ?, None, None) -> None / (int, ?, ?) -> None / (_RNNCellForTest -> ?, None, None) -> None / (LSTMCell -> {LSTMStateTuple | int}, int, ?) -> None / (?, ?, ?) -> None / (RNNCell -> None, None, None) -> None / (RNNCell -> None, ?, ?) -> None'>_zero_state_tensors</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.max_time', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.max_time', title='?'>max_time</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.batch_size', title='?'>batch_size</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments.dtype', title='?'>dtype</a>)
<span class='lineno'> 268</span> 
<span class='lineno'> 269</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state', title='(_BaseAttentionMechanism, ?, ?) -> None'>initial_state</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.self', title='_BaseAttentionMechanism'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.batch_size', title='?'>batch_size</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.dtype', title='?'>dtype</a>):
<span class='lineno'> 270</span>     &quot;&quot;&quot;Creates the initial state values for the `AttentionWrapper` class.
<span class='lineno'> 271</span> 
<span class='lineno'> 272</span>     This is important for AttentionMechanisms that use the previous alignment
<span class='lineno'> 273</span>     to calculate the alignment at the next time step (e.g. monotonic attention).
<span class='lineno'> 274</span> 
<span class='lineno'> 275</span>     The default behavior is to return the same output as initial_alignments.
<span class='lineno'> 276</span> 
<span class='lineno'> 277</span>     Args:
<span class='lineno'> 278</span>       batch_size: `int32` scalar, the batch_size.
<span class='lineno'> 279</span>       dtype: The `dtype`.
<span class='lineno'> 280</span> 
<span class='lineno'> 281</span>     Returns:
<span class='lineno'> 282</span>       A structure of all-zero tensors with shapes as described by `state_size`.
<span class='lineno'> 283</span>     &quot;&quot;&quot;
<span class='lineno'> 284</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.self', title='_BaseAttentionMechanism'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_alignments', title='(_BaseAttentionMechanism, ?, ?) -> None'>initial_alignments</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.batch_size', title='?'>batch_size</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.initial_state.dtype', title='?'>dtype</a>)
<span class='lineno'> 285</span> 
<span class='lineno'> 286</span> 
<span class='lineno'> 287</span> def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score', title='(?, ?, bool) -> None / (?, ?, ?) -> None'>_luong_score</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', title='?'>query</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.keys', title='?'>keys</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.scale', title='bool'>scale</a>):
<span class='lineno'> 288</span>   &quot;&quot;&quot;Implements Luong-style (multiplicative) scoring function.
<span class='lineno'> 289</span> 
<span class='lineno'> 290</span>   This attention has two forms.  The first is standard Luong attention,
<span class='lineno'> 291</span>   as described in:
<span class='lineno'> 292</span> 
<span class='lineno'> 293</span>   Minh-Thang Luong, Hieu Pham, Christopher D. Manning.
<span class='lineno'> 294</span>   &quot;Effective Approaches to Attention-based Neural Machine Translation.&quot;
<span class='lineno'> 295</span>   EMNLP 2015.  https://arxiv.org/abs/1508.04025
<span class='lineno'> 296</span> 
<span class='lineno'> 297</span>   The second is the scaled form inspired partly by the normalized form of
<span class='lineno'> 298</span>   Bahdanau attention.
<span class='lineno'> 299</span> 
<span class='lineno'> 300</span>   To enable the second form, call this function with `scale=True`.
<span class='lineno'> 301</span> 
<span class='lineno'> 302</span>   Args:
<span class='lineno'> 303</span>     query: Tensor, shape `[batch_size, num_units]` to compare to keys.
<span class='lineno'> 304</span>     keys: Processed memory, shape `[batch_size, max_time, num_units]`.
<span class='lineno'> 305</span>     scale: Whether to apply a scale to the score function.
<span class='lineno'> 306</span> 
<span class='lineno'> 307</span>   Returns:
<span class='lineno'> 308</span>     A `[batch_size, max_time]` tensor of unnormalized score values.
<span class='lineno'> 309</span> 
<span class='lineno'> 310</span>   Raises:
<span class='lineno'> 311</span>     ValueError: If `key` and `query` depths do not match.
<span class='lineno'> 312</span>   &quot;&quot;&quot;
<span class='lineno'> 313</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.depth', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.depth', title='?'>depth</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', title='?'>query</a>.get_shape()[-1]
<span class='lineno'> 314</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.key_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.key_units', title='?'>key_units</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.keys', title='?'>keys</a>.get_shape()[-1]
<span class='lineno'> 315</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.depth', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.depth', title='?'>depth</a> != <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.key_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.key_units', title='?'>key_units</a>:
<span class='lineno'> 316</span>     raise ValueError(
<span class='lineno'> 317</span>         &quot;Incompatible or unknown inner dimensions between query and keys.  &quot;
<span class='lineno'> 318</span>         &quot;Query (%s) has units: %s.  Keys (%s) have units: %s.  &quot;
<span class='lineno'> 319</span>         &quot;Perhaps you need to set num_units to the keys&#39; dimension (%s)?&quot;
<span class='lineno'> 320</span>         % (query, depth, keys, key_units, key_units))
<span class='lineno'> 321</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.dtype', title='?'>dtype</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', title='?'>query</a>.dtype
<span class='lineno'> 322</span> 
<span class='lineno'> 323</span>   # Reshape from [batch_size, depth] to [batch_size, 1, depth]
<span class='lineno'> 324</span>   # for matmul.
<span class='lineno'> 325</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', title='None'>query</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.expand_dims', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.expand_dims', title='(None, None, None, None) -> ? / (SparseTensor, int, None, None) -> None / (None, None, None, None) -> None / (LinearOperatorScaledIdentity -> None, int, None, None) -> None / (?, None, None, None) -> None / (?, [int], None, None) -> None / (None, int, None, None) -> None / (None, [int], None, None) -> None / (?, int, None, None) -> None'>expand_dims</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', title='?'>query</a>, 1)
<span class='lineno'> 326</span> 
<span class='lineno'> 327</span>   # Inner product along the query units dimension.
<span class='lineno'> 328</span>   # matmul shapes: query is [batch_size, 1, depth] and
<span class='lineno'> 329</span>   #                keys is [batch_size, max_time, depth].
<span class='lineno'> 330</span>   # the inner product is asked to **transpose keys&#39; inner shape** to get a
<span class='lineno'> 331</span>   # batched matmul on:
<span class='lineno'> 332</span>   #   [batch_size, 1, depth] . [batch_size, depth, max_time]
<span class='lineno'> 333</span>   # resulting in an output shape of:
<span class='lineno'> 334</span>   #   [batch_size, 1, max_time].
<span class='lineno'> 335</span>   # we then squeeze out the center singleton dimension.
<span class='lineno'> 336</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', title='None'>score</a> = <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.matmul', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.matmul', title='(?, {None | PartitionedVariable | VariableV1}, bool, bool, bool, bool, bool, bool, None) -> ? / ([?], {None | PartitionedVariable | VariableV1}, bool, bool, bool, bool, bool, bool, None) -> None / (None, ?, bool, bool, bool, bool, bool, bool, None) -> None / (?, None, bool, bool, bool, bool, bool, bool, None) -> None / (None, None, bool, bool, bool, bool, bool, bool, None) -> None / (?, ?, bool, bool, bool, bool, bool, bool, None) -> None / (SparseTensor, {PartitionedVariable | VariableV1}, bool, bool, bool, bool, bool, bool, None) -> None / (None, SparseTensor, bool, bool, bool, bool, bool, bool, None) -> None / (None, {PartitionedVariable | VariableV1}, bool, bool, bool, bool, bool, bool, None) -> None / (VariableV1, VariableV1, bool, bool, bool, bool, bool, bool, None) -> None'>matmul</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.query', title='None'>query</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.keys', title='?'>keys</a>, transpose_b=True)
<span class='lineno'> 337</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', title='None'>score</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.squeeze', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.squeeze', title='(float, [int], None, None) -> ? / ({None | SparseTensor}, {None | tuple}, None, None) -> None / (?, list, None, None) -> None / (_TensorLike, None, None, None) -> None / (None, None, None, None) -> None / (None, [int], None, None) -> None / (?, [int], None, None) -> None / (float, None, None, None) -> None / (None, list, None, None) -> None / (?, None, None, None) -> None'>squeeze</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', title='None'>score</a>, [1])
<span class='lineno'> 338</span> 
<span class='lineno'> 339</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.scale', title='bool'>scale</a>:
<span class='lineno'> 340</span>     # Scalar used in weight scaling
<span class='lineno'> 341</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.g', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.g', title='{PartitionedVariable | VariableV1}'>g</a> = <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>.<a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', title='(str, [OutputProjectionWrapper -> ?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> ? / (str, [{OutputProjectionWrapper -> ? | int}], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, ?, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [None], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1}'>get_variable</a>(
<span class='lineno'> 342</span>         &quot;attention_g&quot;, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.dtype', title='?'>dtype</a>,
<span class='lineno'> 343</span>         initializer=<a href='../../../../python/ops/init_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops', title='init_ops'>init_ops</a>.<a href='../../../../python/ops/init_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops.ones_initializer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops.ones_initializer', title='<Ones>'>ones_initializer</a>, shape=())
<span class='lineno'> 344</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', title='?'>score</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.g', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.g', title='{PartitionedVariable | VariableV1}'>g</a> * <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', title='None'>score</a>
<span class='lineno'> 345</span>   return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score.score', title='None'>score</a>
<span class='lineno'> 346</span> 
<span class='lineno'> 347</span> 
<span class='lineno'> 348</span> class <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention', title='<LuongAttention>'>LuongAttention</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism', title='<_BaseAttentionMechanism>'>_BaseAttentionMechanism</a>):
<span class='lineno'> 349</span>   &quot;&quot;&quot;Implements Luong-style (multiplicative) attention scoring.
<span class='lineno'> 350</span> 
<span class='lineno'> 351</span>   This attention has two forms.  The first is standard Luong attention,
<span class='lineno'> 352</span>   as described in:
<span class='lineno'> 353</span> 
<span class='lineno'> 354</span>   Minh-Thang Luong, Hieu Pham, Christopher D. Manning.
<span class='lineno'> 355</span>   &quot;Effective Approaches to Attention-based Neural Machine Translation.&quot;
<span class='lineno'> 356</span>   EMNLP 2015.  https://arxiv.org/abs/1508.04025
<span class='lineno'> 357</span> 
<span class='lineno'> 358</span>   The second is the scaled form inspired partly by the normalized form of
<span class='lineno'> 359</span>   Bahdanau attention.
<span class='lineno'> 360</span> 
<span class='lineno'> 361</span>   To enable the second form, construct the object with parameter
<span class='lineno'> 362</span>   `scale=True`.
<span class='lineno'> 363</span>   &quot;&quot;&quot;
<span class='lineno'> 364</span> 
<span class='lineno'> 365</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__', title='? -> ?'>__init__</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.self', title='LuongAttention'>self</a>,
<span class='lineno'> 366</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.num_units', title='?'>num_units</a>,
<span class='lineno'> 367</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.memory', title='?'>memory</a>,
<span class='lineno'> 368</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>=None,
<span class='lineno'> 369</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.scale', title='bool'>scale</a>=False,
<span class='lineno'> 370</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.probability_fn', title='None'>probability_fn</a>=None,
<span class='lineno'> 371</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.score_mask_value', title='None'>score_mask_value</a>=None,
<span class='lineno'> 372</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.dtype', title='None'>dtype</a>=None,
<span class='lineno'> 373</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.name', title='str'>name</a>=&quot;LuongAttention&quot;):
<span class='lineno'> 374</span>     &quot;&quot;&quot;Construct the AttentionMechanism mechanism.
<span class='lineno'> 375</span> 
<span class='lineno'> 376</span>     Args:
<span class='lineno'> 377</span>       num_units: The depth of the attention mechanism.
<span class='lineno'> 378</span>       memory: The memory to query; usually the output of an RNN encoder.  This
<span class='lineno'> 379</span>         tensor should be shaped `[batch_size, max_time, ...]`.
<span class='lineno'> 380</span>       memory_sequence_length: (optional) Sequence lengths for the batch entries
<span class='lineno'> 381</span>         in memory.  If provided, the memory tensor rows are masked with zeros
<span class='lineno'> 382</span>         for values past the respective sequence lengths.
<span class='lineno'> 383</span>       scale: Python boolean.  Whether to scale the energy term.
<span class='lineno'> 384</span>       probability_fn: (optional) A `callable`.  Converts the score to
<span class='lineno'> 385</span>         probabilities.  The default is `tf.nn.softmax`. Other options include
<span class='lineno'> 386</span>         `tf.contrib.seq2seq.hardmax` and `tf.contrib.sparsemax.sparsemax`.
<span class='lineno'> 387</span>         Its signature should be: `probabilities = probability_fn(score)`.
<span class='lineno'> 388</span>       score_mask_value: (optional) The mask value for score before passing into
<span class='lineno'> 389</span>         `probability_fn`. The default is -inf. Only used if
<span class='lineno'> 390</span>         `memory_sequence_length` is not None.
<span class='lineno'> 391</span>       dtype: The data type for the memory layer of the attention mechanism.
<span class='lineno'> 392</span>       name: Name to use when creating ops.
<span class='lineno'> 393</span>     &quot;&quot;&quot;
<span class='lineno'> 394</span>     # For LuongAttention, we only transform the memory layer; thus
<span class='lineno'> 395</span>     # num_units **must** match expected the query depth.
<span class='lineno'> 396</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.probability_fn', title='None'>probability_fn</a> is None:
<span class='lineno'> 397</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.probability_fn', title='({PartitionedVariable | VariableV1}, None, None, None) -> None / (Function, ?, None, None) -> None / (?, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / (None, None, None, None) -> None'>probability_fn</a> = <a href='../../../../python/ops/nn_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.nn_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.nn_ops', title='nn_ops'>nn_ops</a>.<a href='../../../../python/ops/nn_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.nn_ops.softmax', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.nn_ops.softmax', title='({PartitionedVariable | VariableV1}, None, None, None) -> None / (Function, ?, None, None) -> None / (?, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / (None, None, None, None) -> None'>softmax</a>
<span class='lineno'> 398</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.dtype', title='None'>dtype</a> is None:
<span class='lineno'> 399</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.dtype', title='DType'>dtype</a> = <a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', title='dtypes'>dtypes</a>.<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.float32', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.float32', title='DType'>float32</a>
<span class='lineno'> 400</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.wrapped_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.wrapped_probability_fn', title='(?, ?) -> None'>wrapped_probability_fn</a> = lambda <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.lambda%655.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.lambda%655.score', title='?'>score</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.lambda%655._', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.lambda%655._', title='?'>_</a>: <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.probability_fn', title='({PartitionedVariable | VariableV1}, None, None, None) -> None / (Function, ?, None, None) -> None / (?, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / (None, None, None, None) -> None'>probability_fn</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.lambda%655.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.lambda%655.score', title='?'>score</a>)
<span class='lineno'> 401</span>     super(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention', title='<LuongAttention>'>LuongAttention</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.self', title='LuongAttention'>self</a>).__init__(
<span class='lineno'> 402</span>         query_layer=None,
<span class='lineno'> 403</span>         memory_layer=<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', title='core'>layers_core</a>.<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', title='<Dense>'>Dense</a>(
<span class='lineno'> 404</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.num_units', title='?'>num_units</a>, name=&quot;memory_layer&quot;, use_bias=False, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.dtype', title='DType'>dtype</a>),
<span class='lineno'> 405</span>         memory=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.memory', title='?'>memory</a>,
<span class='lineno'> 406</span>         probability_fn=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.wrapped_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.wrapped_probability_fn', title='(?, ?) -> None'>wrapped_probability_fn</a>,
<span class='lineno'> 407</span>         memory_sequence_length=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>,
<span class='lineno'> 408</span>         score_mask_value=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.score_mask_value', title='None'>score_mask_value</a>,
<span class='lineno'> 409</span>         name=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.name', title='str'>name</a>)
<span class='lineno'> 410</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.self', title='LuongAttention'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention._num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention._num_units', title='?'>_num_units</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.num_units', title='?'>num_units</a>
<span class='lineno'> 411</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.self', title='LuongAttention'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention._scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention._scale', title='bool'>_scale</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.scale', title='bool'>scale</a>
<span class='lineno'> 412</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.self', title='LuongAttention'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention._name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention._name', title='str'>_name</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__init__.name', title='str'>name</a>
<span class='lineno'> 413</span> 
<span class='lineno'> 414</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__', title='(LuongAttention, ?, ?) -> (?, ?)'>__call__</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.self', title='LuongAttention'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.query', title='?'>query</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.state', title='?'>state</a>):
<span class='lineno'> 415</span>     &quot;&quot;&quot;Score the query based on the keys and values.
<span class='lineno'> 416</span> 
<span class='lineno'> 417</span>     Args:
<span class='lineno'> 418</span>       query: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 419</span>         `[batch_size, query_depth]`.
<span class='lineno'> 420</span>       state: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 421</span>         `[batch_size, alignments_size]`
<span class='lineno'> 422</span>         (`alignments_size` is memory&#39;s `max_time`).
<span class='lineno'> 423</span> 
<span class='lineno'> 424</span>     Returns:
<span class='lineno'> 425</span>       alignments: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 426</span>         `[batch_size, alignments_size]` (`alignments_size` is memory&#39;s
<span class='lineno'> 427</span>         `max_time`).
<span class='lineno'> 428</span>     &quot;&quot;&quot;
<span class='lineno'> 429</span>     with <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>.<a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.variable_scope', title='<variable_scope>'>variable_scope</a>(None, &quot;luong_attention&quot;, [<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.query', title='?'>query</a>]):
<span class='lineno'> 430</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.score', title='None'>score</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score', title='(?, ?, bool) -> None / (?, ?, ?) -> None'>_luong_score</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.query', title='?'>query</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.self', title='LuongAttention'>self</a>._keys, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.self', title='LuongAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention._scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention._scale', title='bool'>_scale</a>)
<span class='lineno'> 431</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.alignments', title='?'>alignments</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.self', title='LuongAttention'>self</a>._probability_fn(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.score', title='None'>score</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.state', title='?'>state</a>)
<span class='lineno'> 432</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.next_state', title='?'>next_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.alignments', title='?'>alignments</a>
<span class='lineno'> 433</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.alignments', title='?'>alignments</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongAttention.__call__.next_state', title='?'>next_state</a>
<span class='lineno'> 434</span> 
<span class='lineno'> 435</span> 
<span class='lineno'> 436</span> def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score', title='(?, ?, ?) -> None / (?, ?, bool) -> None'>_bahdanau_score</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', title='?'>processed_query</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.keys', title='?'>keys</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.normalize', title='bool'>normalize</a>):
<span class='lineno'> 437</span>   &quot;&quot;&quot;Implements Bahdanau-style (additive) scoring function.
<span class='lineno'> 438</span> 
<span class='lineno'> 439</span>   This attention has two forms.  The first is Bhandanau attention,
<span class='lineno'> 440</span>   as described in:
<span class='lineno'> 441</span> 
<span class='lineno'> 442</span>   Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio.
<span class='lineno'> 443</span>   &quot;Neural Machine Translation by Jointly Learning to Align and Translate.&quot;
<span class='lineno'> 444</span>   ICLR 2015. https://arxiv.org/abs/1409.0473
<span class='lineno'> 445</span> 
<span class='lineno'> 446</span>   The second is the normalized form.  This form is inspired by the
<span class='lineno'> 447</span>   weight normalization article:
<span class='lineno'> 448</span> 
<span class='lineno'> 449</span>   Tim Salimans, Diederik P. Kingma.
<span class='lineno'> 450</span>   &quot;Weight Normalization: A Simple Reparameterization to Accelerate
<span class='lineno'> 451</span>    Training of Deep Neural Networks.&quot;
<span class='lineno'> 452</span>   https://arxiv.org/abs/1602.07868
<span class='lineno'> 453</span> 
<span class='lineno'> 454</span>   To enable the second form, set `normalize=True`.
<span class='lineno'> 455</span> 
<span class='lineno'> 456</span>   Args:
<span class='lineno'> 457</span>     processed_query: Tensor, shape `[batch_size, num_units]` to compare to keys.
<span class='lineno'> 458</span>     keys: Processed memory, shape `[batch_size, max_time, num_units]`.
<span class='lineno'> 459</span>     normalize: Whether to normalize the score function.
<span class='lineno'> 460</span> 
<span class='lineno'> 461</span>   Returns:
<span class='lineno'> 462</span>     A `[batch_size, max_time]` tensor of unnormalized score values.
<span class='lineno'> 463</span>   &quot;&quot;&quot;
<span class='lineno'> 464</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.dtype', title='?'>dtype</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', title='?'>processed_query</a>.dtype
<span class='lineno'> 465</span>   # Get the number of hidden units from the trailing dimension of keys
<span class='lineno'> 466</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.num_units', title='?'>num_units</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.keys', title='?'>keys</a>.shape[2].value or <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.keys', title='?'>keys</a>)[2]
<span class='lineno'> 467</span>   # Reshape from [batch_size, ...] to [batch_size, 1, ...] for broadcasting.
<span class='lineno'> 468</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', title='None'>processed_query</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.expand_dims', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.expand_dims', title='(None, None, None, None) -> ? / (SparseTensor, int, None, None) -> None / (None, None, None, None) -> None / (LinearOperatorScaledIdentity -> None, int, None, None) -> None / (?, None, None, None) -> None / (?, [int], None, None) -> None / (None, int, None, None) -> None / (None, [int], None, None) -> None / (?, int, None, None) -> None'>expand_dims</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', title='?'>processed_query</a>, 1)
<span class='lineno'> 469</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.v', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.v', title='{PartitionedVariable | VariableV1}'>v</a> = <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>.<a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', title='(str, [OutputProjectionWrapper -> ?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> ? / (str, [{OutputProjectionWrapper -> ? | int}], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, ?, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [None], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1}'>get_variable</a>(
<span class='lineno'> 470</span>       &quot;attention_v&quot;, [<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.num_units', title='?'>num_units</a>], dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.dtype', title='?'>dtype</a>)
<span class='lineno'> 471</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.normalize', title='bool'>normalize</a>:
<span class='lineno'> 472</span>     # Scalar used in weight normalization
<span class='lineno'> 473</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.g', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.g', title='{PartitionedVariable | VariableV1}'>g</a> = <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>.<a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', title='(str, [OutputProjectionWrapper -> ?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> ? / (str, [{OutputProjectionWrapper -> ? | int}], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, ?, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [None], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1}'>get_variable</a>(
<span class='lineno'> 474</span>         &quot;attention_g&quot;, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.dtype', title='?'>dtype</a>,
<span class='lineno'> 475</span>         initializer=<a href='../../../../python/ops/init_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops', title='init_ops'>init_ops</a>.<a href='../../../../python/ops/init_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops.constant_initializer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops.constant_initializer', title='<Constant>'>constant_initializer</a>(math.sqrt((1. / <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.num_units', title='?'>num_units</a>))),
<span class='lineno'> 476</span>         shape=())
<span class='lineno'> 477</span>     # Bias added prior to the nonlinearity
<span class='lineno'> 478</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.b', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.b', title='{PartitionedVariable | VariableV1}'>b</a> = <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>.<a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', title='(str, [OutputProjectionWrapper -> ?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> ? / (str, [{OutputProjectionWrapper -> ? | int}], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, ?, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [None], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1}'>get_variable</a>(
<span class='lineno'> 479</span>         &quot;attention_b&quot;, [<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.num_units', title='?'>num_units</a>], dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.dtype', title='?'>dtype</a>,
<span class='lineno'> 480</span>         initializer=<a href='../../../../python/ops/init_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops', title='init_ops'>init_ops</a>.<a href='../../../../python/ops/init_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops.zeros_initializer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.init_ops.zeros_initializer', title='<Zeros>'>zeros_initializer</a>())
<span class='lineno'> 481</span>     # normed_v = g * v / ||v||
<span class='lineno'> 482</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.normed_v', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.normed_v', title='{PartitionedVariable | VariableV1}'>normed_v</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.g', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.g', title='{PartitionedVariable | VariableV1}'>g</a> * <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.v', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.v', title='{PartitionedVariable | VariableV1}'>v</a> * <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/gen_math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.gen_math_ops.rsqrt', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.gen_math_ops.rsqrt', title='(float, None) -> ? / (?, None) -> ? / (None, None) -> ? / ({IndexedSlices | SparseTensor}, None) -> ?'>rsqrt</a>(
<span class='lineno'> 483</span>         <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.reduce_sum', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.reduce_sum', title='(?, list, None, None, None, None) -> ? / (None, list, None, None, None, None) -> None / ({IndexedSlices | None | SparseTensor}, list, None, None, None, None) -> None / (SparseTensor, int, None, None, None, None) -> None / (?, None, None, None, None, None) -> None / (None, None, None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, int, None, None, None, None) -> None / (ExpRelaxedOneHotCategorical -> {IndexedSlices | SparseTensor}, None, None, None, None, None) -> None / (None, [int], None, None, None, None) -> None'>reduce_sum</a>(<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.square', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.square', title='(InverseGamma -> None, None) -> ? / ({None | VariableV1}, None) -> SparseTensor / (Tensor, None) -> SparseTensor / (SparseTensor, None) -> SparseTensor / ({None | TensorArray | tuple}, None) -> SparseTensor / (?, None) -> SparseTensor / (None, None) -> SparseTensor / (float, None) -> SparseTensor / ({IndexedSlices | SparseTensor}, None) -> SparseTensor / ({IndexedSlices | None | SparseTensor}, None) -> SparseTensor'>square</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.v', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.v', title='{PartitionedVariable | VariableV1}'>v</a>)))
<span class='lineno'> 484</span>     return <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.reduce_sum', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.reduce_sum', title='(?, list, None, None, None, None) -> ? / (None, list, None, None, None, None) -> None / ({IndexedSlices | None | SparseTensor}, list, None, None, None, None) -> None / (SparseTensor, int, None, None, None, None) -> None / (?, None, None, None, None, None) -> None / (None, None, None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, int, None, None, None, None) -> None / (ExpRelaxedOneHotCategorical -> {IndexedSlices | SparseTensor}, None, None, None, None, None) -> None / (None, [int], None, None, None, None) -> None'>reduce_sum</a>(
<span class='lineno'> 485</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.normed_v', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.normed_v', title='{PartitionedVariable | VariableV1}'>normed_v</a> * <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.tanh', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.tanh', title='(SRUCell, float) -> ? / (GRUCell, None) -> SparseTensor / ({IndexedSlices | SparseTensor}, None) -> SparseTensor / (IndyLSTMCell, ?) -> SparseTensor / (WeightNormLSTMCell, ?) -> SparseTensor / (IndRNNCell, None) -> SparseTensor / (LayerNormBasicLSTMCell, None) -> SparseTensor / (WeightNormLSTMCell, None) -> SparseTensor / (?, None) -> SparseTensor / (None, None) -> SparseTensor'>tanh</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.keys', title='?'>keys</a> + <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', title='None'>processed_query</a> + <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.b', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.b', title='{PartitionedVariable | VariableV1}'>b</a>), [2])
<span class='lineno'> 486</span>   else:
<span class='lineno'> 487</span>     return <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.reduce_sum', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.reduce_sum', title='(?, list, None, None, None, None) -> ? / (None, list, None, None, None, None) -> None / ({IndexedSlices | None | SparseTensor}, list, None, None, None, None) -> None / (SparseTensor, int, None, None, None, None) -> None / (?, None, None, None, None, None) -> None / (None, None, None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, int, None, None, None, None) -> None / (ExpRelaxedOneHotCategorical -> {IndexedSlices | SparseTensor}, None, None, None, None, None) -> None / (None, [int], None, None, None, None) -> None'>reduce_sum</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.v', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.v', title='{PartitionedVariable | VariableV1}'>v</a> * <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.tanh', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.tanh', title='(SRUCell, float) -> ? / (GRUCell, None) -> SparseTensor / ({IndexedSlices | SparseTensor}, None) -> SparseTensor / (IndyLSTMCell, ?) -> SparseTensor / (WeightNormLSTMCell, ?) -> SparseTensor / (IndRNNCell, None) -> SparseTensor / (LayerNormBasicLSTMCell, None) -> SparseTensor / (WeightNormLSTMCell, None) -> SparseTensor / (?, None) -> SparseTensor / (None, None) -> SparseTensor'>tanh</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.keys', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.keys', title='?'>keys</a> + <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score.processed_query', title='None'>processed_query</a>), [2])
<span class='lineno'> 488</span> 
<span class='lineno'> 489</span> 
<span class='lineno'> 490</span> class <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention', title='<BahdanauAttention>'>BahdanauAttention</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism', title='<_BaseAttentionMechanism>'>_BaseAttentionMechanism</a>):
<span class='lineno'> 491</span>   &quot;&quot;&quot;Implements Bahdanau-style (additive) attention.
<span class='lineno'> 492</span> 
<span class='lineno'> 493</span>   This attention has two forms.  The first is Bahdanau attention,
<span class='lineno'> 494</span>   as described in:
<span class='lineno'> 495</span> 
<span class='lineno'> 496</span>   Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio.
<span class='lineno'> 497</span>   &quot;Neural Machine Translation by Jointly Learning to Align and Translate.&quot;
<span class='lineno'> 498</span>   ICLR 2015. https://arxiv.org/abs/1409.0473
<span class='lineno'> 499</span> 
<span class='lineno'> 500</span>   The second is the normalized form.  This form is inspired by the
<span class='lineno'> 501</span>   weight normalization article:
<span class='lineno'> 502</span> 
<span class='lineno'> 503</span>   Tim Salimans, Diederik P. Kingma.
<span class='lineno'> 504</span>   &quot;Weight Normalization: A Simple Reparameterization to Accelerate
<span class='lineno'> 505</span>    Training of Deep Neural Networks.&quot;
<span class='lineno'> 506</span>   https://arxiv.org/abs/1602.07868
<span class='lineno'> 507</span> 
<span class='lineno'> 508</span>   To enable the second form, construct the object with parameter
<span class='lineno'> 509</span>   `normalize=True`.
<span class='lineno'> 510</span>   &quot;&quot;&quot;
<span class='lineno'> 511</span> 
<span class='lineno'> 512</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__', title='? -> ?'>__init__</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.self', title='BahdanauAttention'>self</a>,
<span class='lineno'> 513</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.num_units', title='?'>num_units</a>,
<span class='lineno'> 514</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.memory', title='?'>memory</a>,
<span class='lineno'> 515</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>=None,
<span class='lineno'> 516</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.normalize', title='bool'>normalize</a>=False,
<span class='lineno'> 517</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.probability_fn', title='None'>probability_fn</a>=None,
<span class='lineno'> 518</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.score_mask_value', title='None'>score_mask_value</a>=None,
<span class='lineno'> 519</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.dtype', title='None'>dtype</a>=None,
<span class='lineno'> 520</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.name', title='str'>name</a>=&quot;BahdanauAttention&quot;):
<span class='lineno'> 521</span>     &quot;&quot;&quot;Construct the Attention mechanism.
<span class='lineno'> 522</span> 
<span class='lineno'> 523</span>     Args:
<span class='lineno'> 524</span>       num_units: The depth of the query mechanism.
<span class='lineno'> 525</span>       memory: The memory to query; usually the output of an RNN encoder.  This
<span class='lineno'> 526</span>         tensor should be shaped `[batch_size, max_time, ...]`.
<span class='lineno'> 527</span>       memory_sequence_length (optional): Sequence lengths for the batch entries
<span class='lineno'> 528</span>         in memory.  If provided, the memory tensor rows are masked with zeros
<span class='lineno'> 529</span>         for values past the respective sequence lengths.
<span class='lineno'> 530</span>       normalize: Python boolean.  Whether to normalize the energy term.
<span class='lineno'> 531</span>       probability_fn: (optional) A `callable`.  Converts the score to
<span class='lineno'> 532</span>         probabilities.  The default is `tf.nn.softmax`. Other options include
<span class='lineno'> 533</span>         `tf.contrib.seq2seq.hardmax` and `tf.contrib.sparsemax.sparsemax`.
<span class='lineno'> 534</span>         Its signature should be: `probabilities = probability_fn(score)`.
<span class='lineno'> 535</span>       score_mask_value: (optional): The mask value for score before passing into
<span class='lineno'> 536</span>         `probability_fn`. The default is -inf. Only used if
<span class='lineno'> 537</span>         `memory_sequence_length` is not None.
<span class='lineno'> 538</span>       dtype: The data type for the query and memory layers of the attention
<span class='lineno'> 539</span>         mechanism.
<span class='lineno'> 540</span>       name: Name to use when creating ops.
<span class='lineno'> 541</span>     &quot;&quot;&quot;
<span class='lineno'> 542</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.probability_fn', title='None'>probability_fn</a> is None:
<span class='lineno'> 543</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.probability_fn', title='({PartitionedVariable | VariableV1}, None, None, None) -> None / (Function, ?, None, None) -> None / (?, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / (None, None, None, None) -> None'>probability_fn</a> = <a href='../../../../python/ops/nn_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.nn_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.nn_ops', title='nn_ops'>nn_ops</a>.<a href='../../../../python/ops/nn_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.nn_ops.softmax', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.nn_ops.softmax', title='({PartitionedVariable | VariableV1}, None, None, None) -> None / (Function, ?, None, None) -> None / (?, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / (None, None, None, None) -> None'>softmax</a>
<span class='lineno'> 544</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.dtype', title='None'>dtype</a> is None:
<span class='lineno'> 545</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.dtype', title='DType'>dtype</a> = <a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', title='dtypes'>dtypes</a>.<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.float32', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.float32', title='DType'>float32</a>
<span class='lineno'> 546</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.wrapped_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.wrapped_probability_fn', title='(?, ?) -> None'>wrapped_probability_fn</a> = lambda <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.lambda%656.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.lambda%656.score', title='?'>score</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.lambda%656._', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.lambda%656._', title='?'>_</a>: <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.probability_fn', title='({PartitionedVariable | VariableV1}, None, None, None) -> None / (Function, ?, None, None) -> None / (?, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / (None, None, None, None) -> None'>probability_fn</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.lambda%656.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.lambda%656.score', title='?'>score</a>)
<span class='lineno'> 547</span>     super(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention', title='<BahdanauAttention>'>BahdanauAttention</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.self', title='BahdanauAttention'>self</a>).__init__(
<span class='lineno'> 548</span>         query_layer=<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', title='core'>layers_core</a>.<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', title='<Dense>'>Dense</a>(
<span class='lineno'> 549</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.num_units', title='?'>num_units</a>, name=&quot;query_layer&quot;, use_bias=False, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.dtype', title='DType'>dtype</a>),
<span class='lineno'> 550</span>         memory_layer=<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', title='core'>layers_core</a>.<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', title='<Dense>'>Dense</a>(
<span class='lineno'> 551</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.num_units', title='?'>num_units</a>, name=&quot;memory_layer&quot;, use_bias=False, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.dtype', title='DType'>dtype</a>),
<span class='lineno'> 552</span>         memory=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.memory', title='?'>memory</a>,
<span class='lineno'> 553</span>         probability_fn=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.wrapped_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.wrapped_probability_fn', title='(?, ?) -> None'>wrapped_probability_fn</a>,
<span class='lineno'> 554</span>         memory_sequence_length=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>,
<span class='lineno'> 555</span>         score_mask_value=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.score_mask_value', title='None'>score_mask_value</a>,
<span class='lineno'> 556</span>         name=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.name', title='str'>name</a>)
<span class='lineno'> 557</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.self', title='BahdanauAttention'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._num_units', title='?'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._num_units', title='?'>_num_units</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.num_units', title='?'>num_units</a>
<span class='lineno'> 558</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.self', title='BahdanauAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._normalize', title='bool'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._normalize', title='bool'>_normalize</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.normalize', title='bool'>normalize</a>
<span class='lineno'> 559</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.self', title='BahdanauAttention'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._name', title='str'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._name', title='str'>_name</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__init__.name', title='str'>name</a>
<span class='lineno'> 560</span> 
<span class='lineno'> 561</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__', title='(BahdanauAttention, ?, ?) -> (?, ?)'>__call__</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', title='BahdanauAttention'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.query', title='?'>query</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.state', title='?'>state</a>):
<span class='lineno'> 562</span>     &quot;&quot;&quot;Score the query based on the keys and values.
<span class='lineno'> 563</span> 
<span class='lineno'> 564</span>     Args:
<span class='lineno'> 565</span>       query: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 566</span>         `[batch_size, query_depth]`.
<span class='lineno'> 567</span>       state: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 568</span>         `[batch_size, alignments_size]`
<span class='lineno'> 569</span>         (`alignments_size` is memory&#39;s `max_time`).
<span class='lineno'> 570</span> 
<span class='lineno'> 571</span>     Returns:
<span class='lineno'> 572</span>       alignments: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 573</span>         `[batch_size, alignments_size]` (`alignments_size` is memory&#39;s
<span class='lineno'> 574</span>         `max_time`).
<span class='lineno'> 575</span>     &quot;&quot;&quot;
<span class='lineno'> 576</span>     with <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>.<a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.variable_scope', title='<variable_scope>'>variable_scope</a>(None, &quot;bahdanau_attention&quot;, [<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.query', title='?'>query</a>]):
<span class='lineno'> 577</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.processed_query', title='?'>processed_query</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', title='BahdanauAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', title='BahdanauAttention -> ? / _BaseAttentionMechanism -> ? / BahdanauMonotonicAttention -> ?'>query_layer</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.query', title='?'>query</a>) if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', title='BahdanauAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', title='BahdanauAttention -> ? / _BaseAttentionMechanism -> ? / BahdanauMonotonicAttention -> ?'>query_layer</a> else <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.query', title='?'>query</a>
<span class='lineno'> 578</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.score', title='None'>score</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score', title='(?, ?, ?) -> None / (?, ?, bool) -> None'>_bahdanau_score</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.processed_query', title='?'>processed_query</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', title='BahdanauAttention'>self</a>._keys, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', title='BahdanauAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention._normalize', title='bool'>_normalize</a>)
<span class='lineno'> 579</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.alignments', title='?'>alignments</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.self', title='BahdanauAttention'>self</a>._probability_fn(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.score', title='None'>score</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.state', title='?'>state</a>)
<span class='lineno'> 580</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.next_state', title='?'>next_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.alignments', title='?'>alignments</a>
<span class='lineno'> 581</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.alignments', title='?'>alignments</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauAttention.__call__.next_state', title='?'>next_state</a>
<span class='lineno'> 582</span> 
<span class='lineno'> 583</span> 
<span class='lineno'> 584</span> def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod', title='? -> None / int -> None'>safe_cumprod</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', title='int'>x</a>, *args, **kwargs):
<span class='lineno'> 585</span>   &quot;&quot;&quot;Computes cumprod of x in logspace using cumsum to avoid underflow.
<span class='lineno'> 586</span> 
<span class='lineno'> 587</span>   The cumprod function and its gradient can result in numerical instabilities
<span class='lineno'> 588</span>   when its argument has very small and/or zero values.  As long as the argument
<span class='lineno'> 589</span>   is all positive, we can instead compute the cumulative product as
<span class='lineno'> 590</span>   exp(cumsum(log(x))).  This function can be called identically to tf.cumprod.
<span class='lineno'> 591</span> 
<span class='lineno'> 592</span>   Args:
<span class='lineno'> 593</span>     x: Tensor to take the cumulative product of.
<span class='lineno'> 594</span>     *args: Passed on to cumsum; these are identical to those in cumprod.
<span class='lineno'> 595</span>     **kwargs: Passed on to cumsum; these are identical to those in cumprod.
<span class='lineno'> 596</span>   Returns:
<span class='lineno'> 597</span>     Cumulative product of x.
<span class='lineno'> 598</span>   &quot;&quot;&quot;
<span class='lineno'> 599</span>   with <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.name_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.name_scope', title='{(None, str, list) -> ? / (None, str, (?, ?, float)) -> {name_scope | variable_scope} / (None, str, [bool]) -> {name_scope | variable_scope} / (None, str, (?, ?, None)) -> {name_scope | variable_scope} / (None, str, [None]) -> {name_scope | variable_scope} / (None, str, [?]) -> {name_scope | variable_scope} / (str, None, None) -> {name_scope | variable_scope} / (None, str, ?) -> {name_scope | variable_scope} / (None, str, [{IndexedSlices | None | SparseTensor}]) -> {name_scope | variable_scope} | <name_scope>}'>name_scope</a>(None, &quot;SafeCumprod&quot;, [<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', title='int'>x</a>]):
<span class='lineno'> 600</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', title='None'>x</a> = <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', title='(SparseTensor -> None, None, None, None) -> ? / (SparseTensor -> None, None, None, None) -> None / ({None | int}, None, None, None) -> None / (int, None, None, None) -> None / (?, None, None, None) -> None / (None, DType, None, None) -> None / (?, DType, None, None) -> None / (None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / ({IndexedSlices | SparseTensor}, DType, None, None) -> None'>convert_to_tensor</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', title='int'>x</a>, name=&quot;x&quot;)
<span class='lineno'> 601</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.tiny', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.tiny', title='?'>tiny</a> = np.finfo(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', title='None'>x</a>.dtype.as_numpy_dtype).tiny
<span class='lineno'> 602</span>     return <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/gen_math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.gen_math_ops.exp', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.gen_math_ops.exp', title='(Tensor, None) -> ? / (SparseTensor, None) -> ? / (PowerTransform -> None, None) -> ? / ({IndexedSlices | SparseTensor}, None) -> ? / (float, None) -> ? / (?, None) -> ? / (None, None) -> ? / (VariableV1, None) -> ? / (int, None) -> ? / (Geometric -> {IndexedSlices | SparseTensor}, None) -> ?'>exp</a>(<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.cumsum', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.cumsum', title='(None, ?, bool, bool, None) -> None / (?, ?, bool, bool, None) -> None / (VariableV1, int, bool, bool, None) -> None / ({IndexedSlices | SparseTensor}, int, bool, bool, None) -> None / (None, int, bool, bool, None) -> None / (?, int, bool, bool, None) -> None'>cumsum</a>(
<span class='lineno'> 603</span>         <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/gen_math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.gen_math_ops.log', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.gen_math_ops.log', title='(Gamma -> None, None) -> ? / (SparseTensor, None) -> ? / (VariableV1, None) -> ? / (float, None) -> ? / (ExpRelaxedOneHotCategorical -> None, None) -> ? / (None, None) -> ? / ({IndexedSlices | SparseTensor}, None) -> ? / (?, None) -> ? / (_Gumbel -> None, None) -> ? / (int, None) -> ?'>log</a>(<a href='../../../../python/ops/clip_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.clip_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.clip_ops', title='clip_ops'>clip_ops</a>.<a href='../../../../python/ops/clip_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.clip_ops.clip_by_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.clip_ops.clip_by_value', title='(None, None, int, None) -> ? / (?, None, None, None) -> None / (None, None, None, None) -> None / (float, float, float, None) -> None / ({IndexedSlices | SparseTensor}, int, int, None) -> None / (?, int, int, None) -> None / (SparseTensor, None, None, None) -> None / (None, ?, ?, None) -> None / (float, None, None, None) -> None'>clip_by_value</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.x', title='None'>x</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.tiny', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod.tiny', title='?'>tiny</a>, 1)), *args, **kwargs))
<span class='lineno'> 604</span> 
<span class='lineno'> 605</span> 
<span class='lineno'> 606</span> def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention', title='(None, ?, ?) -> None / (?, ?, ?) -> None'>monotonic_attention</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', title='?'>previous_attention</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.mode', title='?'>mode</a>):
<span class='lineno'> 607</span>   &quot;&quot;&quot;Compute monotonic attention distribution from choosing probabilities.
<span class='lineno'> 608</span> 
<span class='lineno'> 609</span>   Monotonic attention implies that the input sequence is processed in an
<span class='lineno'> 610</span>   explicitly left-to-right manner when generating the output sequence.  In
<span class='lineno'> 611</span>   addition, once an input sequence element is attended to at a given output
<span class='lineno'> 612</span>   timestep, elements occurring before it cannot be attended to at subsequent
<span class='lineno'> 613</span>   output timesteps.  This function generates attention distributions according
<span class='lineno'> 614</span>   to these assumptions.  For more information, see `Online and Linear-Time
<span class='lineno'> 615</span>   Attention by Enforcing Monotonic Alignments`.
<span class='lineno'> 616</span> 
<span class='lineno'> 617</span>   Args:
<span class='lineno'> 618</span>     p_choose_i: Probability of choosing input sequence/memory element i.  Should
<span class='lineno'> 619</span>       be of shape (batch_size, input_sequence_length), and should all be in the
<span class='lineno'> 620</span>       range [0, 1].
<span class='lineno'> 621</span>     previous_attention: The attention distribution from the previous output
<span class='lineno'> 622</span>       timestep.  Should be of shape (batch_size, input_sequence_length).  For
<span class='lineno'> 623</span>       the first output timestep, preevious_attention[n] should be [1, 0, 0, ...,
<span class='lineno'> 624</span>       0] for all n in [0, ... batch_size - 1].
<span class='lineno'> 625</span>     mode: How to compute the attention distribution.  Must be one of
<span class='lineno'> 626</span>       &#39;recursive&#39;, &#39;parallel&#39;, or &#39;hard&#39;.
<span class='lineno'> 627</span>         * &#39;recursive&#39; uses tf.scan to recursively compute the distribution.
<span class='lineno'> 628</span>           This is slowest but is exact, general, and does not suffer from
<span class='lineno'> 629</span>           numerical instabilities.
<span class='lineno'> 630</span>         * &#39;parallel&#39; uses parallelized cumulative-sum and cumulative-product
<span class='lineno'> 631</span>           operations to compute a closed-form solution to the recurrence
<span class='lineno'> 632</span>           relation defining the attention distribution.  This makes it more
<span class='lineno'> 633</span>           efficient than &#39;recursive&#39;, but it requires numerical checks which
<span class='lineno'> 634</span>           make the distribution non-exact.  This can be a problem in particular
<span class='lineno'> 635</span>           when input_sequence_length is long and/or p_choose_i has entries very
<span class='lineno'> 636</span>           close to 0 or 1.
<span class='lineno'> 637</span>         * &#39;hard&#39; requires that the probabilities in p_choose_i are all either 0
<span class='lineno'> 638</span>           or 1, and subsequently uses a more efficient and exact solution.
<span class='lineno'> 639</span> 
<span class='lineno'> 640</span>   Returns:
<span class='lineno'> 641</span>     A tensor of shape (batch_size, input_sequence_length) representing the
<span class='lineno'> 642</span>     attention distributions for each sequence in the batch.
<span class='lineno'> 643</span> 
<span class='lineno'> 644</span>   Raises:
<span class='lineno'> 645</span>     ValueError: mode is not one of &#39;recursive&#39;, &#39;parallel&#39;, &#39;hard&#39;.
<span class='lineno'> 646</span>   &quot;&quot;&quot;
<span class='lineno'> 647</span>   # Force things to be tensors
<span class='lineno'> 648</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a> = <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', title='(SparseTensor -> None, None, None, None) -> ? / (SparseTensor -> None, None, None, None) -> None / ({None | int}, None, None, None) -> None / (int, None, None, None) -> None / (?, None, None, None) -> None / (None, DType, None, None) -> None / (?, DType, None, None) -> None / (None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / ({IndexedSlices | SparseTensor}, DType, None, None) -> None'>convert_to_tensor</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a>, name=&quot;p_choose_i&quot;)
<span class='lineno'> 649</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', title='None'>previous_attention</a> = <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', title='(SparseTensor -> None, None, None, None) -> ? / (SparseTensor -> None, None, None, None) -> None / ({None | int}, None, None, None) -> None / (int, None, None, None) -> None / (?, None, None, None) -> None / (None, DType, None, None) -> None / (?, DType, None, None) -> None / (None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / ({IndexedSlices | SparseTensor}, DType, None, None) -> None'>convert_to_tensor</a>(
<span class='lineno'> 650</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', title='?'>previous_attention</a>, name=&quot;previous_attention&quot;)
<span class='lineno'> 651</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.mode', title='?'>mode</a> == &quot;recursive&quot;:
<span class='lineno'> 652</span>     # Use .shape[0].value when it&#39;s not None, or fall back on symbolic shape
<span class='lineno'> 653</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.batch_size', title='?'>batch_size</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a>.shape[0].value or <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a>)[0]
<span class='lineno'> 654</span>     # Compute [1, 1 - p_choose_i[0], 1 - p_choose_i[1], ..., 1 - p_choose_i[-2]]
<span class='lineno'> 655</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.shifted_1mp_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.shifted_1mp_choose_i', title='?'>shifted_1mp_choose_i</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.concat', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.concat', title='((?, [?]), int, str) -> ? / ([[?]], int, str) -> None / ([?], int, str) -> None / ([{None | [int]}], int, str) -> None / ([IndexedSlices -> None], int, str) -> None / ([None], int, str) -> None / (?, int, str) -> None / ((None, None), int, str) -> None / ([{IndexedSlices | SparseTensor}], int, str) -> None'>concat</a>(
<span class='lineno'> 656</span>         [<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.ones', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.ones', title='([None], ?, None) -> ? / ([?], ?, None) -> ? / ((?, int), DType, None) -> ? / (?, DType, None) -> ? / ([?], DType, None) -> ? / (None, DType, None) -> ? / ([None], DType, None) -> ? / ([int], DType, None) -> ? / (LinearOperator -> None, DType, None) -> ?'>ones</a>((<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.batch_size', title='?'>batch_size</a>, 1)), 1 - <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a>[:, :-1]], 1)
<span class='lineno'> 657</span>     # Compute attention distribution recursively as
<span class='lineno'> 658</span>     # q[i] = (1 - p_choose_i[i - 1])*q[i - 1] + previous_attention[i]
<span class='lineno'> 659</span>     # attention[i] = p_choose_i[i]*q[i]
<span class='lineno'> 660</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.attention', title='None'>attention</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a>*<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.transpose', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.transpose', title='(SparseTensor, [int], str, bool) -> ? / (None, (int, int, int), str, bool) -> None / (?, [int], str, bool) -> None / (None, [int], str, bool) -> None / (None, None, str, bool) -> None / (?, ?, str, bool) -> None / (None, ?, str, bool) -> None / (?, None, str, bool) -> None'>transpose</a>(<a href='../../../../python/ops/functional_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.functional_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.functional_ops', title='functional_ops'>functional_ops</a>.<a href='../../../../python/ops/functional_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.functional_ops.scan', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.functional_ops.scan', title='(?, ?, None, int, bool, bool, bool, bool, None) -> None / (? -> ?, {IndexedSlices | SparseTensor}, None, int, bool, bool, bool, bool, None) -> None / ((?, ?) -> None, ?, None, int, bool, bool, bool, bool, None) -> None / ((?, ?) -> bool, ?, None, int, bool, bool, bool, bool, None) -> None / ((?, ?) -> ?, [None], ?, int, bool, bool, bool, bool, None) -> None'>scan</a>(
<span class='lineno'> 661</span>         # Need to use reshape to remind TF of the shape between loop iterations
<span class='lineno'> 662</span>         lambda <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.lambda%657.x', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.lambda%657.x', title='?'>x</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.lambda%657.yz', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.lambda%657.yz', title='?'>yz</a>: <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/gen_array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.gen_array_ops.reshape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.gen_array_ops.reshape', title='({None | [None]}, [int], None) -> ? / ({[DeferredTensor] | [None]}, None, None) -> ? / (None, None, None) -> ? / (?, None, None) -> ? / (None, [int], None) -> ? / (?, [int], None) -> ? / (None, ?, None) -> ? / (None, [?], None) -> ?'>reshape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.lambda%657.yz', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.lambda%657.yz', title='?'>yz</a>[0]*<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.lambda%657.x', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.lambda%657.x', title='?'>x</a> + <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.lambda%657.yz', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.lambda%657.yz', title='?'>yz</a>[1], (<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.batch_size', title='?'>batch_size</a>,)),
<span class='lineno'> 663</span>         # Loop variables yz[0] and yz[1]
<span class='lineno'> 664</span>         [<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.transpose', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.transpose', title='(SparseTensor, [int], str, bool) -> ? / (None, (int, int, int), str, bool) -> None / (?, [int], str, bool) -> None / (None, [int], str, bool) -> None / (None, None, str, bool) -> None / (?, ?, str, bool) -> None / (None, ?, str, bool) -> None / (?, None, str, bool) -> None'>transpose</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.shifted_1mp_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.shifted_1mp_choose_i', title='?'>shifted_1mp_choose_i</a>),
<span class='lineno'> 665</span>          <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.transpose', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.transpose', title='(SparseTensor, [int], str, bool) -> ? / (None, (int, int, int), str, bool) -> None / (?, [int], str, bool) -> None / (None, [int], str, bool) -> None / (None, None, str, bool) -> None / (?, ?, str, bool) -> None / (None, ?, str, bool) -> None / (?, None, str, bool) -> None'>transpose</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', title='None'>previous_attention</a>)],
<span class='lineno'> 666</span>         # Initial value of x is just zeros
<span class='lineno'> 667</span>         <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.zeros', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.zeros', title='(?, None, None) -> ? / ([?], ?, None) -> ? / ([int], ?, None) -> ? / ([?], DType, None) -> ? / (?, ?, None) -> ? / (?, DType, None) -> ? / (None, DType, None) -> ? / (?, {IndexedSlices -> None | SparseTensor -> None}, None) -> ? / ([None], DType, None) -> ? / (TensorShape, DType, None) -> ?'>zeros</a>((<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.batch_size', title='?'>batch_size</a>,))))
<span class='lineno'> 668</span>   elif <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.mode', title='?'>mode</a> == &quot;parallel&quot;:
<span class='lineno'> 669</span>     # safe_cumprod computes cumprod in logspace with numeric checks
<span class='lineno'> 670</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.cumprod_1mp_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.cumprod_1mp_choose_i', title='None'>cumprod_1mp_choose_i</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.safe_cumprod', title='? -> None / int -> None'>safe_cumprod</a>(1 - <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a>, axis=1, exclusive=True)
<span class='lineno'> 671</span>     # Compute recurrence relation solution
<span class='lineno'> 672</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.attention', title='None'>attention</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a>*<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.cumprod_1mp_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.cumprod_1mp_choose_i', title='None'>cumprod_1mp_choose_i</a>*<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.cumsum', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.cumsum', title='(None, ?, bool, bool, None) -> None / (?, ?, bool, bool, None) -> None / (VariableV1, int, bool, bool, None) -> None / ({IndexedSlices | SparseTensor}, int, bool, bool, None) -> None / (None, int, bool, bool, None) -> None / (?, int, bool, bool, None) -> None'>cumsum</a>(
<span class='lineno'> 673</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', title='None'>previous_attention</a> /
<span class='lineno'> 674</span>         # Clip cumprod_1mp to avoid divide-by-zero
<span class='lineno'> 675</span>         <a href='../../../../python/ops/clip_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.clip_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.clip_ops', title='clip_ops'>clip_ops</a>.<a href='../../../../python/ops/clip_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.clip_ops.clip_by_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.clip_ops.clip_by_value', title='(None, None, int, None) -> ? / (?, None, None, None) -> None / (None, None, None, None) -> None / (float, float, float, None) -> None / ({IndexedSlices | SparseTensor}, int, int, None) -> None / (?, int, int, None) -> None / (SparseTensor, None, None, None) -> None / (None, ?, ?, None) -> None / (float, None, None, None) -> None'>clip_by_value</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.cumprod_1mp_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.cumprod_1mp_choose_i', title='None'>cumprod_1mp_choose_i</a>, 1e-10, 1.), axis=1)
<span class='lineno'> 676</span>   elif <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.mode', title='?'>mode</a> == &quot;hard&quot;:
<span class='lineno'> 677</span>     # Remove any probabilities before the index chosen last time step
<span class='lineno'> 678</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a></a> *= <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.cumsum', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.cumsum', title='(None, ?, bool, bool, None) -> None / (?, ?, bool, bool, None) -> None / (VariableV1, int, bool, bool, None) -> None / ({IndexedSlices | SparseTensor}, int, bool, bool, None) -> None / (None, int, bool, bool, None) -> None / (?, int, bool, bool, None) -> None'>cumsum</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.previous_attention', title='None'>previous_attention</a>, axis=1)
<span class='lineno'> 679</span>     # Now, use exclusive cumprod to remove probabilities after the first
<span class='lineno'> 680</span>     # chosen index, like so:
<span class='lineno'> 681</span>     # p_choose_i = [0, 0, 0, 1, 1, 0, 1, 1]
<span class='lineno'> 682</span>     # cumprod(1 - p_choose_i, exclusive=True) = [1, 1, 1, 1, 0, 0, 0, 0]
<span class='lineno'> 683</span>     # Product of above: [0, 0, 0, 1, 0, 0, 0, 0]
<span class='lineno'> 684</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.attention', title='None'>attention</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a>*<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.cumprod', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.cumprod', title='(?, ?, bool, bool, None) -> None / (?, int, bool, bool, None) -> None / (int, int, bool, bool, None) -> None'>cumprod</a>(
<span class='lineno'> 685</span>         1 - <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.p_choose_i', title='None'>p_choose_i</a>, axis=1, exclusive=True)
<span class='lineno'> 686</span>   else:
<span class='lineno'> 687</span>     raise ValueError(&quot;mode must be &#39;recursive&#39;, &#39;parallel&#39;, or &#39;hard&#39;.&quot;)
<span class='lineno'> 688</span>   return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention.attention', title='None'>attention</a>
<span class='lineno'> 689</span> 
<span class='lineno'> 690</span> 
<span class='lineno'> 691</span> def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn', title='(?, ?, ?, ?, None) -> None'>_monotonic_probability_fn</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', title='?'>score</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.previous_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.previous_alignments', title='?'>previous_alignments</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.sigmoid_noise', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.sigmoid_noise', title='?'>sigmoid_noise</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.mode', title='?'>mode</a>,
<span class='lineno'> 692</span>                               <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.seed', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.seed', title='None'>seed</a>=None):
<span class='lineno'> 693</span>   &quot;&quot;&quot;Attention probability function for monotonic attention.
<span class='lineno'> 694</span> 
<span class='lineno'> 695</span>   Takes in unnormalized attention scores, adds pre-sigmoid noise to encourage
<span class='lineno'> 696</span>   the model to make discrete attention decisions, passes them through a sigmoid
<span class='lineno'> 697</span>   to obtain &quot;choosing&quot; probabilities, and then calls monotonic_attention to
<span class='lineno'> 698</span>   obtain the attention distribution.  For more information, see
<span class='lineno'> 699</span> 
<span class='lineno'> 700</span>   Colin Raffel, Minh-Thang Luong, Peter J. Liu, Ron J. Weiss, Douglas Eck,
<span class='lineno'> 701</span>   &quot;Online and Linear-Time Attention by Enforcing Monotonic Alignments.&quot;
<span class='lineno'> 702</span>   ICML 2017.  https://arxiv.org/abs/1704.00784
<span class='lineno'> 703</span> 
<span class='lineno'> 704</span>   Args:
<span class='lineno'> 705</span>     score: Unnormalized attention scores, shape `[batch_size, alignments_size]`
<span class='lineno'> 706</span>     previous_alignments: Previous attention distribution, shape
<span class='lineno'> 707</span>       `[batch_size, alignments_size]`
<span class='lineno'> 708</span>     sigmoid_noise: Standard deviation of pre-sigmoid noise.  Setting this larger
<span class='lineno'> 709</span>       than 0 will encourage the model to produce large attention scores,
<span class='lineno'> 710</span>       effectively making the choosing probabilities discrete and the resulting
<span class='lineno'> 711</span>       attention distribution one-hot.  It should be set to 0 at test-time, and
<span class='lineno'> 712</span>       when hard attention is not desired.
<span class='lineno'> 713</span>     mode: How to compute the attention distribution.  Must be one of
<span class='lineno'> 714</span>       &#39;recursive&#39;, &#39;parallel&#39;, or &#39;hard&#39;.  See the docstring for
<span class='lineno'> 715</span>       `tf.contrib.seq2seq.monotonic_attention` for more information.
<span class='lineno'> 716</span>     seed: (optional) Random seed for pre-sigmoid noise.
<span class='lineno'> 717</span> 
<span class='lineno'> 718</span>   Returns:
<span class='lineno'> 719</span>     A `[batch_size, alignments_size]`-shape tensor corresponding to the
<span class='lineno'> 720</span>     resulting attention distribution.
<span class='lineno'> 721</span>   &quot;&quot;&quot;
<span class='lineno'> 722</span>   # Optionally add pre-sigmoid noise to the scores
<span class='lineno'> 723</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.sigmoid_noise', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.sigmoid_noise', title='?'>sigmoid_noise</a> &gt; 0:
<span class='lineno'> 724</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.noise', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.noise', title='None'>noise</a> = <a href='../../../../python/ops/random_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.random_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.random_ops', title='random_ops'>random_ops</a>.<a href='../../../../python/ops/random_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.random_ops.random_normal', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.random_ops.random_normal', title='{(SparseTensor -> TensorShape, float, float, DType, None, None) -> ? / (?, float, float, DType, None, None) -> None / (TensorShape, float, float, DType, None, None) -> None / ([int], float, float, DType, None, None) -> None / (None, float, float, DType, None, None) -> None / ([?], float, float, DType, None, None) -> None / (?, float, int, DType, None, None) -> None / ((int, int), float, float, DType, None, None) -> None / (?, ?, ?, DType, None, None) -> None / (list, float, float, DType, None, None) -> None | (SparseTensor -> TensorShape, float, float, DType, None, None) -> None / ([int], float, float, DType, None, None) -> None / (None, float, float, DType, None, None) -> None / ([?], float, float, DType, None, None) -> None / (?, float, float, DType, None, None) -> None}'>random_normal</a>(<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', title='?'>score</a>), dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', title='?'>score</a>.dtype,
<span class='lineno'> 725</span>                                      seed=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.seed', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.seed', title='None'>seed</a>)
<span class='lineno'> 726</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', title='None'>score</a></a> += <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.sigmoid_noise', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.sigmoid_noise', title='?'>sigmoid_noise</a>*<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.noise', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.noise', title='None'>noise</a>
<span class='lineno'> 727</span>   # Compute &quot;choosing&quot; probabilities from the attention scores
<span class='lineno'> 728</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.mode', title='?'>mode</a> == &quot;hard&quot;:
<span class='lineno'> 729</span>     # When mode is hard, use a hard sigmoid
<span class='lineno'> 730</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.p_choose_i', title='?'>p_choose_i</a> = <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.cast', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.cast', title='(IndexedSlices -> None, ?, None) -> ? / (SparseTensor -> None, ?, None) -> {IndexedSlices | SparseTensor | SparseTensor -> None} / ({int | str}, SparseTensor -> None, None) -> {int | str} / (IndexedSlices -> None, DType, None) -> {IndexedSlices | IndexedSlices -> None | SparseTensor} / (IndexedSlices -> None, DType -> DType, None) -> {IndexedSlices | IndexedSlices -> None | SparseTensor} / (None, int, None) -> {IndexedSlices | SparseTensor} / (SparseTensor -> None, DType -> DType, None) -> {IndexedSlices | SparseTensor | SparseTensor -> None} / (None, DType, None) -> {IndexedSlices | SparseTensor} / (?, ?, None) -> {IndexedSlices | SparseTensor} / (int, DType, None) -> {IndexedSlices | SparseTensor | int}'>cast</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', title='None'>score</a> &gt; 0, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', title='None'>score</a>.dtype)
<span class='lineno'> 731</span>   else:
<span class='lineno'> 732</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.p_choose_i', title='None'>p_choose_i</a> = <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.sigmoid', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.sigmoid', title='(Bernoulli -> {IndexedSlices | SparseTensor}, None) -> None / (None, None) -> None / (int, None) -> None / (?, None) -> None / ({PartitionedVariable | VariableV1}, None) -> None / (float, None) -> None / (NegativeBinomial -> {IndexedSlices | SparseTensor}, None) -> None'>sigmoid</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.score', title='None'>score</a>)
<span class='lineno'> 733</span>   # Convert from choosing probabilities to attention distribution
<span class='lineno'> 734</span>   return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.monotonic_attention', title='(None, ?, ?) -> None / (?, ?, ?) -> None'>monotonic_attention</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.p_choose_i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.p_choose_i', title='None'>p_choose_i</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.previous_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.previous_alignments', title='?'>previous_alignments</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn.mode', title='?'>mode</a>)
<span class='lineno'> 735</span> 
<span class='lineno'> 736</span> 
<span class='lineno'> 737</span> class <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism', title='<_BaseMonotonicAttentionMechanism>'>_BaseMonotonicAttentionMechanism</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism', title='<_BaseAttentionMechanism>'>_BaseAttentionMechanism</a>):
<span class='lineno'> 738</span>   &quot;&quot;&quot;Base attention mechanism for monotonic attention.
<span class='lineno'> 739</span> 
<span class='lineno'> 740</span>   Simply overrides the initial_alignments function to provide a dirac
<span class='lineno'> 741</span>   distribution, which is needed in order for the monotonic attention
<span class='lineno'> 742</span>   distributions to have the correct behavior.
<span class='lineno'> 743</span>   &quot;&quot;&quot;
<span class='lineno'> 744</span> 
<span class='lineno'> 745</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments', title='(_BaseMonotonicAttentionMechanism, ?, ?) -> None'>initial_alignments</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.self', title='_BaseMonotonicAttentionMechanism'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.batch_size', title='?'>batch_size</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.dtype', title='?'>dtype</a>):
<span class='lineno'> 746</span>     &quot;&quot;&quot;Creates the initial alignment values for the monotonic attentions.
<span class='lineno'> 747</span> 
<span class='lineno'> 748</span>     Initializes to dirac distributions, i.e. [1, 0, 0, ...memory length..., 0]
<span class='lineno'> 749</span>     for all entries in the batch.
<span class='lineno'> 750</span> 
<span class='lineno'> 751</span>     Args:
<span class='lineno'> 752</span>       batch_size: `int32` scalar, the batch_size.
<span class='lineno'> 753</span>       dtype: The `dtype`.
<span class='lineno'> 754</span> 
<span class='lineno'> 755</span>     Returns:
<span class='lineno'> 756</span>       A `dtype` tensor shaped `[batch_size, alignments_size]`
<span class='lineno'> 757</span>       (`alignments_size` is the values&#39; `max_time`).
<span class='lineno'> 758</span>     &quot;&quot;&quot;
<span class='lineno'> 759</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.max_time', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.max_time', title='?'>max_time</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.self', title='_BaseMonotonicAttentionMechanism'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism._alignments_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism._alignments_size', title='?'>_alignments_size</a>
<span class='lineno'> 760</span>     return <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.one_hot', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.one_hot', title='(?, None, None, None, None, None, None) -> ? / (None, _BucketizedColumn -> int, float, float, None, None, None) -> None / (None, _OneHotColumn -> None, None, None, None, None, None) -> None / ({IndexedSlices | None | SparseTensor}, ?, None, None, None, None, None) -> None / (None, ?, bool, bool, None, None, None) -> None / (?, ?, bool, bool, None, None, None) -> None / (?, ?, None, None, None, None, None) -> None / (None, ?, None, None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, ?, None, None, None, None, None) -> None'>one_hot</a>(
<span class='lineno'> 761</span>         <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.zeros', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.zeros', title='(?, None, None) -> ? / ([?], ?, None) -> ? / ([int], ?, None) -> ? / ([?], DType, None) -> ? / (?, ?, None) -> ? / (?, DType, None) -> ? / (None, DType, None) -> ? / (?, {IndexedSlices -> None | SparseTensor -> None}, None) -> ? / ([None], DType, None) -> ? / (TensorShape, DType, None) -> ?'>zeros</a>((<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.batch_size', title='?'>batch_size</a>,), dtype=<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', title='dtypes'>dtypes</a>.<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.int32', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.int32', title='DType'>int32</a>), <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.max_time', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.max_time', title='?'>max_time</a>,
<span class='lineno'> 762</span>         dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism.initial_alignments.dtype', title='?'>dtype</a>)
<span class='lineno'> 763</span> 
<span class='lineno'> 764</span> 
<span class='lineno'> 765</span> class <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention', title='<BahdanauMonotonicAttention>'>BahdanauMonotonicAttention</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism', title='<_BaseMonotonicAttentionMechanism>'>_BaseMonotonicAttentionMechanism</a>):
<span class='lineno'> 766</span>   &quot;&quot;&quot;Monotonic attention mechanism with Bahadanau-style energy function.
<span class='lineno'> 767</span> 
<span class='lineno'> 768</span>   This type of attention enforces a monotonic constraint on the attention
<span class='lineno'> 769</span>   distributions; that is once the model attends to a given point in the memory
<span class='lineno'> 770</span>   it can&#39;t attend to any prior points at subsequence output timesteps.  It
<span class='lineno'> 771</span>   achieves this by using the _monotonic_probability_fn instead of softmax to
<span class='lineno'> 772</span>   construct its attention distributions.  Since the attention scores are passed
<span class='lineno'> 773</span>   through a sigmoid, a learnable scalar bias parameter is applied after the
<span class='lineno'> 774</span>   score function and before the sigmoid.  Otherwise, it is equivalent to
<span class='lineno'> 775</span>   BahdanauAttention.  This approach is proposed in
<span class='lineno'> 776</span> 
<span class='lineno'> 777</span>   Colin Raffel, Minh-Thang Luong, Peter J. Liu, Ron J. Weiss, Douglas Eck,
<span class='lineno'> 778</span>   &quot;Online and Linear-Time Attention by Enforcing Monotonic Alignments.&quot;
<span class='lineno'> 779</span>   ICML 2017.  https://arxiv.org/abs/1704.00784
<span class='lineno'> 780</span>   &quot;&quot;&quot;
<span class='lineno'> 781</span> 
<span class='lineno'> 782</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__', title='? -> ?'>__init__</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', title='BahdanauMonotonicAttention'>self</a>,
<span class='lineno'> 783</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.num_units', title='?'>num_units</a>,
<span class='lineno'> 784</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.memory', title='?'>memory</a>,
<span class='lineno'> 785</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>=None,
<span class='lineno'> 786</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.normalize', title='bool'>normalize</a>=False,
<span class='lineno'> 787</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.score_mask_value', title='None'>score_mask_value</a>=None,
<span class='lineno'> 788</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.sigmoid_noise', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.sigmoid_noise', title='float'>sigmoid_noise</a>=0.,
<span class='lineno'> 789</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.sigmoid_noise_seed', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.sigmoid_noise_seed', title='None'>sigmoid_noise_seed</a>=None,
<span class='lineno'> 790</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.score_bias_init', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.score_bias_init', title='float'>score_bias_init</a>=0.,
<span class='lineno'> 791</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.mode', title='str'>mode</a>=&quot;parallel&quot;,
<span class='lineno'> 792</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.dtype', title='None'>dtype</a>=None,
<span class='lineno'> 793</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.name', title='str'>name</a>=&quot;BahdanauMonotonicAttention&quot;):
<span class='lineno'> 794</span>     &quot;&quot;&quot;Construct the Attention mechanism.
<span class='lineno'> 795</span> 
<span class='lineno'> 796</span>     Args:
<span class='lineno'> 797</span>       num_units: The depth of the query mechanism.
<span class='lineno'> 798</span>       memory: The memory to query; usually the output of an RNN encoder.  This
<span class='lineno'> 799</span>         tensor should be shaped `[batch_size, max_time, ...]`.
<span class='lineno'> 800</span>       memory_sequence_length (optional): Sequence lengths for the batch entries
<span class='lineno'> 801</span>         in memory.  If provided, the memory tensor rows are masked with zeros
<span class='lineno'> 802</span>         for values past the respective sequence lengths.
<span class='lineno'> 803</span>       normalize: Python boolean.  Whether to normalize the energy term.
<span class='lineno'> 804</span>       score_mask_value: (optional): The mask value for score before passing into
<span class='lineno'> 805</span>         `probability_fn`. The default is -inf. Only used if
<span class='lineno'> 806</span>         `memory_sequence_length` is not None.
<span class='lineno'> 807</span>       sigmoid_noise: Standard deviation of pre-sigmoid noise.  See the docstring
<span class='lineno'> 808</span>         for `_monotonic_probability_fn` for more information.
<span class='lineno'> 809</span>       sigmoid_noise_seed: (optional) Random seed for pre-sigmoid noise.
<span class='lineno'> 810</span>       score_bias_init: Initial value for score bias scalar.  It&#39;s recommended to
<span class='lineno'> 811</span>         initialize this to a negative value when the length of the memory is
<span class='lineno'> 812</span>         large.
<span class='lineno'> 813</span>       mode: How to compute the attention distribution.  Must be one of
<span class='lineno'> 814</span>         &#39;recursive&#39;, &#39;parallel&#39;, or &#39;hard&#39;.  See the docstring for
<span class='lineno'> 815</span>         `tf.contrib.seq2seq.monotonic_attention` for more information.
<span class='lineno'> 816</span>       dtype: The data type for the query and memory layers of the attention
<span class='lineno'> 817</span>         mechanism.
<span class='lineno'> 818</span>       name: Name to use when creating ops.
<span class='lineno'> 819</span>     &quot;&quot;&quot;
<span class='lineno'> 820</span>     # Set up the monotonic probability fn with supplied parameters
<span class='lineno'> 821</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.dtype', title='None'>dtype</a> is None:
<span class='lineno'> 822</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.dtype', title='DType'>dtype</a> = <a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', title='dtypes'>dtypes</a>.<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.float32', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.float32', title='DType'>float32</a>
<span class='lineno'> 823</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.wrapped_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.wrapped_probability_fn', title='?'>wrapped_probability_fn</a> = functools.partial(
<span class='lineno'> 824</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn', title='(?, ?, ?, ?, None) -> None'>_monotonic_probability_fn</a>, sigmoid_noise=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.sigmoid_noise', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.sigmoid_noise', title='float'>sigmoid_noise</a>, mode=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.mode', title='str'>mode</a>,
<span class='lineno'> 825</span>         seed=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.sigmoid_noise_seed', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.sigmoid_noise_seed', title='None'>sigmoid_noise_seed</a>)
<span class='lineno'> 826</span>     super(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention', title='<BahdanauMonotonicAttention>'>BahdanauMonotonicAttention</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', title='BahdanauMonotonicAttention'>self</a>).__init__(
<span class='lineno'> 827</span>         query_layer=<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', title='core'>layers_core</a>.<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', title='<Dense>'>Dense</a>(
<span class='lineno'> 828</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.num_units', title='?'>num_units</a>, name=&quot;query_layer&quot;, use_bias=False, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.dtype', title='DType'>dtype</a>),
<span class='lineno'> 829</span>         memory_layer=<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', title='core'>layers_core</a>.<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', title='<Dense>'>Dense</a>(
<span class='lineno'> 830</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.num_units', title='?'>num_units</a>, name=&quot;memory_layer&quot;, use_bias=False, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.dtype', title='DType'>dtype</a>),
<span class='lineno'> 831</span>         memory=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.memory', title='?'>memory</a>,
<span class='lineno'> 832</span>         probability_fn=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.wrapped_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.wrapped_probability_fn', title='?'>wrapped_probability_fn</a>,
<span class='lineno'> 833</span>         memory_sequence_length=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>,
<span class='lineno'> 834</span>         score_mask_value=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.score_mask_value', title='None'>score_mask_value</a>,
<span class='lineno'> 835</span>         name=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.name', title='str'>name</a>)
<span class='lineno'> 836</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', title='BahdanauMonotonicAttention'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._num_units', title='?'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._num_units', title='?'>_num_units</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.num_units', title='?'>num_units</a>
<span class='lineno'> 837</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', title='BahdanauMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._normalize', title='bool'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._normalize', title='bool'>_normalize</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.normalize', title='bool'>normalize</a>
<span class='lineno'> 838</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', title='BahdanauMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._name', title='str'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._name', title='str'>_name</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.name', title='str'>name</a>
<span class='lineno'> 839</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.self', title='BahdanauMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._score_bias_init', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._score_bias_init', title='float'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._score_bias_init', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._score_bias_init', title='float'>_score_bias_init</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.score_bias_init', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__init__.score_bias_init', title='float'>score_bias_init</a>
<span class='lineno'> 840</span> 
<span class='lineno'> 841</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__', title='(BahdanauMonotonicAttention, ?, ?) -> (?, ?)'>__call__</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', title='BahdanauMonotonicAttention'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.query', title='?'>query</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.state', title='?'>state</a>):
<span class='lineno'> 842</span>     &quot;&quot;&quot;Score the query based on the keys and values.
<span class='lineno'> 843</span> 
<span class='lineno'> 844</span>     Args:
<span class='lineno'> 845</span>       query: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 846</span>         `[batch_size, query_depth]`.
<span class='lineno'> 847</span>       state: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 848</span>         `[batch_size, alignments_size]`
<span class='lineno'> 849</span>         (`alignments_size` is memory&#39;s `max_time`).
<span class='lineno'> 850</span> 
<span class='lineno'> 851</span>     Returns:
<span class='lineno'> 852</span>       alignments: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 853</span>         `[batch_size, alignments_size]` (`alignments_size` is memory&#39;s
<span class='lineno'> 854</span>         `max_time`).
<span class='lineno'> 855</span>     &quot;&quot;&quot;
<span class='lineno'> 856</span>     with <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>.<a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.variable_scope', title='<variable_scope>'>variable_scope</a>(
<span class='lineno'> 857</span>         None, &quot;bahdanau_monotonic_attention&quot;, [<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.query', title='?'>query</a>]):
<span class='lineno'> 858</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.processed_query', title='?'>processed_query</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', title='BahdanauMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', title='BahdanauAttention -> ? / _BaseAttentionMechanism -> ? / BahdanauMonotonicAttention -> ?'>query_layer</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.query', title='?'>query</a>) if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', title='BahdanauMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseAttentionMechanism.query_layer', title='BahdanauAttention -> ? / _BaseAttentionMechanism -> ? / BahdanauMonotonicAttention -> ?'>query_layer</a> else <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.query', title='?'>query</a>
<span class='lineno'> 859</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score', title='None'>score</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._bahdanau_score', title='(?, ?, ?) -> None / (?, ?, bool) -> None'>_bahdanau_score</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.processed_query', title='?'>processed_query</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', title='BahdanauMonotonicAttention'>self</a>._keys, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', title='BahdanauMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._normalize', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._normalize', title='bool'>_normalize</a>)
<span class='lineno'> 860</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score_bias', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score_bias', title='{PartitionedVariable | VariableV1}'>score_bias</a> = <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>.<a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', title='(str, [OutputProjectionWrapper -> ?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> ? / (str, [{OutputProjectionWrapper -> ? | int}], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, ?, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [None], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1}'>get_variable</a>(
<span class='lineno'> 861</span>           &quot;attention_score_bias&quot;, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.processed_query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.processed_query', title='?'>processed_query</a>.dtype,
<span class='lineno'> 862</span>           initializer=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', title='BahdanauMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._score_bias_init', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention._score_bias_init', title='float'>_score_bias_init</a>)
<span class='lineno'> 863</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score', title='?'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score', title='None'>score</a></a> += <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score_bias', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score_bias', title='{PartitionedVariable | VariableV1}'>score_bias</a>
<span class='lineno'> 864</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.alignments', title='?'>alignments</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.self', title='BahdanauMonotonicAttention'>self</a>._probability_fn(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.score', title='?'>score</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.state', title='?'>state</a>)
<span class='lineno'> 865</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.next_state', title='?'>next_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.alignments', title='?'>alignments</a>
<span class='lineno'> 866</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.alignments', title='?'>alignments</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.BahdanauMonotonicAttention.__call__.next_state', title='?'>next_state</a>
<span class='lineno'> 867</span> 
<span class='lineno'> 868</span> 
<span class='lineno'> 869</span> class <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention', title='<LuongMonotonicAttention>'>LuongMonotonicAttention</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._BaseMonotonicAttentionMechanism', title='<_BaseMonotonicAttentionMechanism>'>_BaseMonotonicAttentionMechanism</a>):
<span class='lineno'> 870</span>   &quot;&quot;&quot;Monotonic attention mechanism with Luong-style energy function.
<span class='lineno'> 871</span> 
<span class='lineno'> 872</span>   This type of attention enforces a monotonic constraint on the attention
<span class='lineno'> 873</span>   distributions; that is once the model attends to a given point in the memory
<span class='lineno'> 874</span>   it can&#39;t attend to any prior points at subsequence output timesteps.  It
<span class='lineno'> 875</span>   achieves this by using the _monotonic_probability_fn instead of softmax to
<span class='lineno'> 876</span>   construct its attention distributions.  Otherwise, it is equivalent to
<span class='lineno'> 877</span>   LuongAttention.  This approach is proposed in
<span class='lineno'> 878</span> 
<span class='lineno'> 879</span>   Colin Raffel, Minh-Thang Luong, Peter J. Liu, Ron J. Weiss, Douglas Eck,
<span class='lineno'> 880</span>   &quot;Online and Linear-Time Attention by Enforcing Monotonic Alignments.&quot;
<span class='lineno'> 881</span>   ICML 2017.  https://arxiv.org/abs/1704.00784
<span class='lineno'> 882</span>   &quot;&quot;&quot;
<span class='lineno'> 883</span> 
<span class='lineno'> 884</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__', title='? -> ?'>__init__</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', title='LuongMonotonicAttention'>self</a>,
<span class='lineno'> 885</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.num_units', title='?'>num_units</a>,
<span class='lineno'> 886</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.memory', title='?'>memory</a>,
<span class='lineno'> 887</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>=None,
<span class='lineno'> 888</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.scale', title='bool'>scale</a>=False,
<span class='lineno'> 889</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.score_mask_value', title='None'>score_mask_value</a>=None,
<span class='lineno'> 890</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.sigmoid_noise', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.sigmoid_noise', title='float'>sigmoid_noise</a>=0.,
<span class='lineno'> 891</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.sigmoid_noise_seed', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.sigmoid_noise_seed', title='None'>sigmoid_noise_seed</a>=None,
<span class='lineno'> 892</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.score_bias_init', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.score_bias_init', title='float'>score_bias_init</a>=0.,
<span class='lineno'> 893</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.mode', title='str'>mode</a>=&quot;parallel&quot;,
<span class='lineno'> 894</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.dtype', title='None'>dtype</a>=None,
<span class='lineno'> 895</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.name', title='str'>name</a>=&quot;LuongMonotonicAttention&quot;):
<span class='lineno'> 896</span>     &quot;&quot;&quot;Construct the Attention mechanism.
<span class='lineno'> 897</span> 
<span class='lineno'> 898</span>     Args:
<span class='lineno'> 899</span>       num_units: The depth of the query mechanism.
<span class='lineno'> 900</span>       memory: The memory to query; usually the output of an RNN encoder.  This
<span class='lineno'> 901</span>         tensor should be shaped `[batch_size, max_time, ...]`.
<span class='lineno'> 902</span>       memory_sequence_length (optional): Sequence lengths for the batch entries
<span class='lineno'> 903</span>         in memory.  If provided, the memory tensor rows are masked with zeros
<span class='lineno'> 904</span>         for values past the respective sequence lengths.
<span class='lineno'> 905</span>       scale: Python boolean.  Whether to scale the energy term.
<span class='lineno'> 906</span>       score_mask_value: (optional): The mask value for score before passing into
<span class='lineno'> 907</span>         `probability_fn`. The default is -inf. Only used if
<span class='lineno'> 908</span>         `memory_sequence_length` is not None.
<span class='lineno'> 909</span>       sigmoid_noise: Standard deviation of pre-sigmoid noise.  See the docstring
<span class='lineno'> 910</span>         for `_monotonic_probability_fn` for more information.
<span class='lineno'> 911</span>       sigmoid_noise_seed: (optional) Random seed for pre-sigmoid noise.
<span class='lineno'> 912</span>       score_bias_init: Initial value for score bias scalar.  It&#39;s recommended to
<span class='lineno'> 913</span>         initialize this to a negative value when the length of the memory is
<span class='lineno'> 914</span>         large.
<span class='lineno'> 915</span>       mode: How to compute the attention distribution.  Must be one of
<span class='lineno'> 916</span>         &#39;recursive&#39;, &#39;parallel&#39;, or &#39;hard&#39;.  See the docstring for
<span class='lineno'> 917</span>         `tf.contrib.seq2seq.monotonic_attention` for more information.
<span class='lineno'> 918</span>       dtype: The data type for the query and memory layers of the attention
<span class='lineno'> 919</span>         mechanism.
<span class='lineno'> 920</span>       name: Name to use when creating ops.
<span class='lineno'> 921</span>     &quot;&quot;&quot;
<span class='lineno'> 922</span>     # Set up the monotonic probability fn with supplied parameters
<span class='lineno'> 923</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.dtype', title='None'>dtype</a> is None:
<span class='lineno'> 924</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.dtype', title='DType'>dtype</a> = <a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', title='dtypes'>dtypes</a>.<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.float32', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.float32', title='DType'>float32</a>
<span class='lineno'> 925</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.wrapped_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.wrapped_probability_fn', title='?'>wrapped_probability_fn</a> = functools.partial(
<span class='lineno'> 926</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._monotonic_probability_fn', title='(?, ?, ?, ?, None) -> None'>_monotonic_probability_fn</a>, sigmoid_noise=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.sigmoid_noise', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.sigmoid_noise', title='float'>sigmoid_noise</a>, mode=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.mode', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.mode', title='str'>mode</a>,
<span class='lineno'> 927</span>         seed=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.sigmoid_noise_seed', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.sigmoid_noise_seed', title='None'>sigmoid_noise_seed</a>)
<span class='lineno'> 928</span>     super(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention', title='<LuongMonotonicAttention>'>LuongMonotonicAttention</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', title='LuongMonotonicAttention'>self</a>).__init__(
<span class='lineno'> 929</span>         query_layer=None,
<span class='lineno'> 930</span>         memory_layer=<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', title='core'>layers_core</a>.<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', title='<Dense>'>Dense</a>(
<span class='lineno'> 931</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.num_units', title='?'>num_units</a>, name=&quot;memory_layer&quot;, use_bias=False, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.dtype', title='DType'>dtype</a>),
<span class='lineno'> 932</span>         memory=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.memory', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.memory', title='?'>memory</a>,
<span class='lineno'> 933</span>         probability_fn=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.wrapped_probability_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.wrapped_probability_fn', title='?'>wrapped_probability_fn</a>,
<span class='lineno'> 934</span>         memory_sequence_length=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.memory_sequence_length', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.memory_sequence_length', title='None'>memory_sequence_length</a>,
<span class='lineno'> 935</span>         score_mask_value=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.score_mask_value', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.score_mask_value', title='None'>score_mask_value</a>,
<span class='lineno'> 936</span>         name=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.name', title='str'>name</a>)
<span class='lineno'> 937</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', title='LuongMonotonicAttention'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._num_units', title='?'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._num_units', title='?'>_num_units</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.num_units', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.num_units', title='?'>num_units</a>
<span class='lineno'> 938</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', title='LuongMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._scale', title='bool'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._scale', title='bool'>_scale</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.scale', title='bool'>scale</a>
<span class='lineno'> 939</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', title='LuongMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._score_bias_init', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._score_bias_init', title='float'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._score_bias_init', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._score_bias_init', title='float'>_score_bias_init</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.score_bias_init', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.score_bias_init', title='float'>score_bias_init</a>
<span class='lineno'> 940</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.self', title='LuongMonotonicAttention'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._name', title='str'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._name', title='str'>_name</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__init__.name', title='str'>name</a>
<span class='lineno'> 941</span> 
<span class='lineno'> 942</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__', title='(LuongMonotonicAttention, ?, ?) -> (?, ?)'>__call__</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.self', title='LuongMonotonicAttention'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.query', title='?'>query</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.state', title='?'>state</a>):
<span class='lineno'> 943</span>     &quot;&quot;&quot;Score the query based on the keys and values.
<span class='lineno'> 944</span> 
<span class='lineno'> 945</span>     Args:
<span class='lineno'> 946</span>       query: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 947</span>         `[batch_size, query_depth]`.
<span class='lineno'> 948</span>       state: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 949</span>         `[batch_size, alignments_size]`
<span class='lineno'> 950</span>         (`alignments_size` is memory&#39;s `max_time`).
<span class='lineno'> 951</span> 
<span class='lineno'> 952</span>     Returns:
<span class='lineno'> 953</span>       alignments: Tensor of dtype matching `self.values` and shape
<span class='lineno'> 954</span>         `[batch_size, alignments_size]` (`alignments_size` is memory&#39;s
<span class='lineno'> 955</span>         `max_time`).
<span class='lineno'> 956</span>     &quot;&quot;&quot;
<span class='lineno'> 957</span>     with <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>.<a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.variable_scope', title='<variable_scope>'>variable_scope</a>(None, &quot;luong_monotonic_attention&quot;,
<span class='lineno'> 958</span>                                        [<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.query', title='?'>query</a>]):
<span class='lineno'> 959</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score', title='None'>score</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._luong_score', title='(?, ?, bool) -> None / (?, ?, ?) -> None'>_luong_score</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.query', title='?'>query</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.self', title='LuongMonotonicAttention'>self</a>._keys, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.self', title='LuongMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._scale', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._scale', title='bool'>_scale</a>)
<span class='lineno'> 960</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score_bias', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score_bias', title='{PartitionedVariable | VariableV1}'>score_bias</a> = <a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope', title='variable_scope'>variable_scope</a>.<a href='../../../../python/ops/variable_scope.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.variable_scope.get_variable', title='(str, [OutputProjectionWrapper -> ?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> ? / (str, [{OutputProjectionWrapper -> ? | int}], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, ?, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [int], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [?], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (str, [None], None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1} / (?, None, None, None, None, None, None, None, None, bool, None, None, None, int, int) -> {PartitionedVariable | VariableV1}'>get_variable</a>(
<span class='lineno'> 961</span>           &quot;attention_score_bias&quot;, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.query', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.query', title='?'>query</a>.dtype,
<span class='lineno'> 962</span>           initializer=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.self', title='LuongMonotonicAttention'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._score_bias_init', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention._score_bias_init', title='float'>_score_bias_init</a>)
<span class='lineno'> 963</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score', title='?'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score', title='None'>score</a></a> += <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score_bias', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score_bias', title='{PartitionedVariable | VariableV1}'>score_bias</a>
<span class='lineno'> 964</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.alignments', title='?'>alignments</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.self', title='LuongMonotonicAttention'>self</a>._probability_fn(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.score', title='?'>score</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.state', title='?'>state</a>)
<span class='lineno'> 965</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.next_state', title='?'>next_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.alignments', title='?'>alignments</a>
<span class='lineno'> 966</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.alignments', title='?'>alignments</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.LuongMonotonicAttention.__call__.next_state', title='?'>next_state</a>
<span class='lineno'> 967</span> 
<span class='lineno'> 968</span> 
<span class='lineno'> 969</span> class <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', title='<AttentionWrapperState>'>AttentionWrapperState</a>(
<span class='lineno'> 970</span>     collections.namedtuple(&quot;AttentionWrapperState&quot;,
<span class='lineno'> 971</span>                            (&quot;cell_state&quot;, &quot;attention&quot;, &quot;time&quot;, &quot;alignments&quot;,
<span class='lineno'> 972</span>                             &quot;alignment_history&quot;, &quot;attention_state&quot;))):
<span class='lineno'> 973</span>   &quot;&quot;&quot;`namedtuple` storing the state of a `AttentionWrapper`.
<span class='lineno'> 974</span> 
<span class='lineno'> 975</span>   Contains:
<span class='lineno'> 976</span> 
<span class='lineno'> 977</span>     - `cell_state`: The state of the wrapped `RNNCell` at the previous time
<span class='lineno'> 978</span>       step.
<span class='lineno'> 979</span>     - `attention`: The attention emitted at the previous time step.
<span class='lineno'> 980</span>     - `time`: int32 scalar containing the current time step.
<span class='lineno'> 981</span>     - `alignments`: A single or tuple of `Tensor`(s) containing the alignments
<span class='lineno'> 982</span>        emitted at the previous time step for each attention mechanism.
<span class='lineno'> 983</span>     - `alignment_history`: (if enabled) a single or tuple of `TensorArray`(s)
<span class='lineno'> 984</span>        containing alignment matrices from all time steps for each attention
<span class='lineno'> 985</span>        mechanism. Call `stack()` on each to convert to a `Tensor`.
<span class='lineno'> 986</span>     - `attention_state`: A single or tuple of nested objects
<span class='lineno'> 987</span>        containing attention mechanism state for each attention mechanism.
<span class='lineno'> 988</span>        The objects may contain Tensors or TensorArrays.
<span class='lineno'> 989</span>   &quot;&quot;&quot;
<span class='lineno'> 990</span> 
<span class='lineno'> 991</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone', title='AttentionWrapperState -> None'>clone</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.self', title='AttentionWrapperState'>self</a>, **kwargs):
<span class='lineno'> 992</span>     &quot;&quot;&quot;Clone this object, overriding components provided by kwargs.
<span class='lineno'> 993</span> 
<span class='lineno'> 994</span>     The new state fields&#39; shape must match original state fields&#39; shape. This
<span class='lineno'> 995</span>     will be validated, and original fields&#39; shape will be propagated to new
<span class='lineno'> 996</span>     fields.
<span class='lineno'> 997</span> 
<span class='lineno'> 998</span>     Example:
<span class='lineno'> 999</span> 
<span class='lineno'>1000</span>     ```python
<span class='lineno'>1001</span>     initial_state = attention_wrapper.zero_state(dtype=..., batch_size=...)
<span class='lineno'>1002</span>     initial_state = initial_state.clone(cell_state=encoder_state)
<span class='lineno'>1003</span>     ```
<span class='lineno'>1004</span> 
<span class='lineno'>1005</span>     Args:
<span class='lineno'>1006</span>       **kwargs: Any properties of the state object to replace in the returned
<span class='lineno'>1007</span>         `AttentionWrapperState`.
<span class='lineno'>1008</span> 
<span class='lineno'>1009</span>     Returns:
<span class='lineno'>1010</span>       A new `AttentionWrapperState` whose properties are the same as
<span class='lineno'>1011</span>       this one, except any overridden properties as provided in `kwargs`.
<span class='lineno'>1012</span>     &quot;&quot;&quot;
<span class='lineno'>1013</span>     def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape', title='(?, ?) -> SparseTensor'>with_same_shape</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.old', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.old', title='?'>old</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.new', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.new', title='?'>new</a>):
<span class='lineno'>1014</span>       &quot;&quot;&quot;Check and set new tensor&#39;s shape.&quot;&quot;&quot;
<span class='lineno'>1015</span>       if isinstance(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.old', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.old', title='?'>old</a>, <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.Tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.Tensor', title='<Tensor>'>Tensor</a>) and isinstance(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.new', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.new', title='?'>new</a>, <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.Tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.Tensor', title='<Tensor>'>Tensor</a>):
<span class='lineno'>1016</span>         return <a href='../../../framework/python/framework/tensor_util.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework.python.framework.tensor_util', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework.python.framework.tensor_util', title='tensor_util'>tensor_util</a>.<a href='../../../framework/python/framework/tensor_util.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework.python.framework.tensor_util.with_same_shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.framework.python.framework.tensor_util.with_same_shape', title='(?, ?) -> SparseTensor'>with_same_shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.old', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.old', title='?'>old</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.new', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.new', title='?'>new</a>)
<span class='lineno'>1017</span>       return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.new', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape.new', title='?'>new</a>
<span class='lineno'>1018</span> 
<span class='lineno'>1019</span>     return <a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>.<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', title='? -> ? -> ? / ? -> ? -> None / ? -> TensorArray -> None / ? -> None / list -> list -> None / ? -> _DotString -> _DotString / (_TensorLike, None) -> ? / (IndexedSlices -> None, None) -> None / (None, None) -> None / ({IndexedSlices | SparseTensor}, None) -> None / (?, None) -> None / ({None | [None]}, None) -> None / ({? -> bool | None}, None) -> None / (Tensor, None) -> None -> None / (CondContext, ?) -> {IndexedSlices | SparseTensor | list} -> {IndexedSlices | SparseTensor | list} / ? -> TensorArray -> None -> TensorArray -> None'>map_structure</a>(
<span class='lineno'>1020</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.with_same_shape', title='(?, ?) -> SparseTensor'>with_same_shape</a>,
<span class='lineno'>1021</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.self', title='AttentionWrapperState'>self</a>,
<span class='lineno'>1022</span>         super(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', title='<AttentionWrapperState>'>AttentionWrapperState</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState.clone.self', title='AttentionWrapperState'>self</a>)._replace(**kwargs))
<span class='lineno'>1023</span> 
<span class='lineno'>1024</span> 
<span class='lineno'>1025</span> def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax', title='(?, None) -> None'>hardmax</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', title='?'>logits</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.name', title='None'>name</a>=None):
<span class='lineno'>1026</span>   &quot;&quot;&quot;Returns batched one-hot vectors.
<span class='lineno'>1027</span> 
<span class='lineno'>1028</span>   The depth index containing the `1` is that of the maximum logit value.
<span class='lineno'>1029</span> 
<span class='lineno'>1030</span>   Args:
<span class='lineno'>1031</span>     logits: A batch tensor of logit values.
<span class='lineno'>1032</span>     name: Name to use when creating ops.
<span class='lineno'>1033</span>   Returns:
<span class='lineno'>1034</span>     A batched one-hot tensor.
<span class='lineno'>1035</span>   &quot;&quot;&quot;
<span class='lineno'>1036</span>   with <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.name_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.name_scope', title='{(None, str, list) -> ? / (None, str, (?, ?, float)) -> {name_scope | variable_scope} / (None, str, [bool]) -> {name_scope | variable_scope} / (None, str, (?, ?, None)) -> {name_scope | variable_scope} / (None, str, [None]) -> {name_scope | variable_scope} / (None, str, [?]) -> {name_scope | variable_scope} / (str, None, None) -> {name_scope | variable_scope} / (None, str, ?) -> {name_scope | variable_scope} / (None, str, [{IndexedSlices | None | SparseTensor}]) -> {name_scope | variable_scope} | <name_scope>}'>name_scope</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.name', title='None'>name</a>, &quot;Hardmax&quot;, [<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', title='?'>logits</a>]):
<span class='lineno'>1037</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', title='None'>logits</a> = <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.convert_to_tensor', title='(SparseTensor -> None, None, None, None) -> ? / (SparseTensor -> None, None, None, None) -> None / ({None | int}, None, None, None) -> None / (int, None, None, None) -> None / (?, None, None, None) -> None / (None, DType, None, None) -> None / (?, DType, None, None) -> None / (None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, None, None, None) -> None / ({IndexedSlices | SparseTensor}, DType, None, None) -> None'>convert_to_tensor</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', title='?'>logits</a>, name=&quot;logits&quot;)
<span class='lineno'>1038</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', title='None'>logits</a>.get_shape()[-1].value is not None:
<span class='lineno'>1039</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.depth', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.depth', title='?'>depth</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', title='None'>logits</a>.get_shape()[-1].value
<span class='lineno'>1040</span>     else:
<span class='lineno'>1041</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.depth', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.depth', title='?'>depth</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', title='None'>logits</a>)[-1]
<span class='lineno'>1042</span>     return <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.one_hot', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.one_hot', title='(?, None, None, None, None, None, None) -> ? / (None, _BucketizedColumn -> int, float, float, None, None, None) -> None / (None, _OneHotColumn -> None, None, None, None, None, None) -> None / ({IndexedSlices | None | SparseTensor}, ?, None, None, None, None, None) -> None / (None, ?, bool, bool, None, None, None) -> None / (?, ?, bool, bool, None, None, None) -> None / (?, ?, None, None, None, None, None) -> None / (None, ?, None, None, None, None, None) -> None / ({IndexedSlices | SparseTensor}, ?, None, None, None, None, None) -> None'>one_hot</a>(
<span class='lineno'>1043</span>         <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.argmax', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.argmax', title='(None, None, None, None, DType) -> None / (OneHotCategorical -> {IndexedSlices | SparseTensor}, None, None, None, DType) -> None / (Categorical -> {IndexedSlices | SparseTensor}, None, None, None, DType) -> None / (None, int, None, None, DType) -> None / (?, None, None, None, DType) -> None / (?, int, None, None, DType) -> None'>argmax</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', title='None'>logits</a>, -1), <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.depth', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.depth', title='?'>depth</a>, dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.hardmax.logits', title='None'>logits</a>.dtype)
<span class='lineno'>1044</span> 
<span class='lineno'>1045</span> 
<span class='lineno'>1046</span> def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention', title='(?, None, list, None) -> (None, ?, ?) / (?, ?, ?, ?) -> (None, ?, ?)'>_compute_attention</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_mechanism', title='?'>attention_mechanism</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.cell_output', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.cell_output', title='None'>cell_output</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_state', title='list'>attention_state</a>,
<span class='lineno'>1047</span>                        <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_layer', title='None'>attention_layer</a>):
<span class='lineno'>1048</span>   &quot;&quot;&quot;Computes the attention and alignments for a given attention_mechanism.&quot;&quot;&quot;
<span class='lineno'>1049</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.alignments', title='?'>alignments</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.next_attention_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.next_attention_state', title='?'>next_attention_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_mechanism', title='?'>attention_mechanism</a>(
<span class='lineno'>1050</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.cell_output', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.cell_output', title='None'>cell_output</a>, state=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_state', title='list'>attention_state</a>)
<span class='lineno'>1051</span> 
<span class='lineno'>1052</span>   # Reshape from [batch_size, memory_time] to [batch_size, 1, memory_time]
<span class='lineno'>1053</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.expanded_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.expanded_alignments', title='None'>expanded_alignments</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.expand_dims', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.expand_dims', title='(None, None, None, None) -> ? / (SparseTensor, int, None, None) -> None / (None, None, None, None) -> None / (LinearOperatorScaledIdentity -> None, int, None, None) -> None / (?, None, None, None) -> None / (?, [int], None, None) -> None / (None, int, None, None) -> None / (None, [int], None, None) -> None / (?, int, None, None) -> None'>expand_dims</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.alignments', title='?'>alignments</a>, 1)
<span class='lineno'>1054</span>   # Context is the inner product of alignments and values along the
<span class='lineno'>1055</span>   # memory time dimension.
<span class='lineno'>1056</span>   # alignments shape is
<span class='lineno'>1057</span>   #   [batch_size, 1, memory_time]
<span class='lineno'>1058</span>   # attention_mechanism.values shape is
<span class='lineno'>1059</span>   #   [batch_size, memory_time, memory_size]
<span class='lineno'>1060</span>   # the batched matmul is over memory_time, so the output shape is
<span class='lineno'>1061</span>   #   [batch_size, 1, memory_size].
<span class='lineno'>1062</span>   # we then squeeze out the singleton dim.
<span class='lineno'>1063</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.context', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.context', title='None'>context</a> = <a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops', title='math_ops'>math_ops</a>.<a href='../../../../python/ops/math_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.matmul', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.math_ops.matmul', title='(?, {None | PartitionedVariable | VariableV1}, bool, bool, bool, bool, bool, bool, None) -> ? / ([?], {None | PartitionedVariable | VariableV1}, bool, bool, bool, bool, bool, bool, None) -> None / (None, ?, bool, bool, bool, bool, bool, bool, None) -> None / (?, None, bool, bool, bool, bool, bool, bool, None) -> None / (None, None, bool, bool, bool, bool, bool, bool, None) -> None / (?, ?, bool, bool, bool, bool, bool, bool, None) -> None / (SparseTensor, {PartitionedVariable | VariableV1}, bool, bool, bool, bool, bool, bool, None) -> None / (None, SparseTensor, bool, bool, bool, bool, bool, bool, None) -> None / (None, {PartitionedVariable | VariableV1}, bool, bool, bool, bool, bool, bool, None) -> None / (VariableV1, VariableV1, bool, bool, bool, bool, bool, bool, None) -> None'>matmul</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.expanded_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.expanded_alignments', title='None'>expanded_alignments</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_mechanism', title='?'>attention_mechanism</a>.values)
<span class='lineno'>1064</span>   <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.context', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.context', title='None'>context</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.squeeze', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.squeeze', title='(float, [int], None, None) -> ? / ({None | SparseTensor}, {None | tuple}, None, None) -> None / (?, list, None, None) -> None / (_TensorLike, None, None, None) -> None / (None, None, None, None) -> None / (None, [int], None, None) -> None / (?, [int], None, None) -> None / (float, None, None, None) -> None / (None, list, None, None) -> None / (?, None, None, None) -> None'>squeeze</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.context', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.context', title='None'>context</a>, [1])
<span class='lineno'>1065</span> 
<span class='lineno'>1066</span>   if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_layer', title='None'>attention_layer</a> is not None:
<span class='lineno'>1067</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention', title='?'>attention</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention_layer', title='None'>attention_layer</a>(<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.concat', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.concat', title='((?, [?]), int, str) -> ? / ([[?]], int, str) -> None / ([?], int, str) -> None / ([{None | [int]}], int, str) -> None / ([IndexedSlices -> None], int, str) -> None / ([None], int, str) -> None / (?, int, str) -> None / ((None, None), int, str) -> None / ([{IndexedSlices | SparseTensor}], int, str) -> None'>concat</a>([<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.cell_output', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.cell_output', title='None'>cell_output</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.context', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.context', title='None'>context</a>], 1))
<span class='lineno'>1068</span>   else:
<span class='lineno'>1069</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention', title='None'>attention</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.context', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.context', title='None'>context</a>
<span class='lineno'>1070</span> 
<span class='lineno'>1071</span>   return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.attention', title='None'>attention</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.alignments', title='?'>alignments</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.next_attention_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention.next_attention_state', title='?'>next_attention_state</a>
<span class='lineno'>1072</span> 
<span class='lineno'>1073</span> 
<span class='lineno'>1074</span> class <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper', title='<AttentionWrapper>'>AttentionWrapper</a>(<a href='../../../../python/ops/rnn_cell_impl.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl', title='rnn_cell_impl'>rnn_cell_impl</a>.<a href='../../../../python/ops/rnn_cell_impl.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl.RNNCell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl.RNNCell', title='<RNNCell>'>RNNCell</a>):
<span class='lineno'>1075</span>   &quot;&quot;&quot;Wraps another `RNNCell` with attention.
<span class='lineno'>1076</span>   &quot;&quot;&quot;
<span class='lineno'>1077</span> 
<span class='lineno'>1078</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__', title='? -> ?'>__init__</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>,
<span class='lineno'>1079</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell', title='?'>cell</a>,
<span class='lineno'>1080</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='?'>attention_mechanism</a>,
<span class='lineno'>1081</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', title='None'>attention_layer_size</a>=None,
<span class='lineno'>1082</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.alignment_history', title='bool'>alignment_history</a>=False,
<span class='lineno'>1083</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell_input_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell_input_fn', title='None'>cell_input_fn</a>=None,
<span class='lineno'>1084</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.output_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.output_attention', title='bool'>output_attention</a>=True,
<span class='lineno'>1085</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.initial_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.initial_cell_state', title='None'>initial_cell_state</a>=None,
<span class='lineno'>1086</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.name', title='None'>name</a>=None,
<span class='lineno'>1087</span>                <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', title='None'>attention_layer</a>=None):
<span class='lineno'>1088</span>     &quot;&quot;&quot;Construct the `AttentionWrapper`.
<span class='lineno'>1089</span> 
<span class='lineno'>1090</span>     **NOTE** If you are using the `BeamSearchDecoder` with a cell wrapped in
<span class='lineno'>1091</span>     `AttentionWrapper`, then you must ensure that:
<span class='lineno'>1092</span> 
<span class='lineno'>1093</span>     - The encoder output has been tiled to `beam_width` via
<span class='lineno'>1094</span>       `tf.contrib.seq2seq.tile_batch` (NOT `tf.tile`).
<span class='lineno'>1095</span>     - The `batch_size` argument passed to the `zero_state` method of this
<span class='lineno'>1096</span>       wrapper is equal to `true_batch_size * beam_width`.
<span class='lineno'>1097</span>     - The initial state created with `zero_state` above contains a
<span class='lineno'>1098</span>       `cell_state` value containing properly tiled final state from the
<span class='lineno'>1099</span>       encoder.
<span class='lineno'>1100</span> 
<span class='lineno'>1101</span>     An example:
<span class='lineno'>1102</span> 
<span class='lineno'>1103</span>     ```
<span class='lineno'>1104</span>     tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(
<span class='lineno'>1105</span>         encoder_outputs, multiplier=beam_width)
<span class='lineno'>1106</span>     tiled_encoder_final_state = tf.conrib.seq2seq.tile_batch(
<span class='lineno'>1107</span>         encoder_final_state, multiplier=beam_width)
<span class='lineno'>1108</span>     tiled_sequence_length = tf.contrib.seq2seq.tile_batch(
<span class='lineno'>1109</span>         sequence_length, multiplier=beam_width)
<span class='lineno'>1110</span>     attention_mechanism = MyFavoriteAttentionMechanism(
<span class='lineno'>1111</span>         num_units=attention_depth,
<span class='lineno'>1112</span>         memory=tiled_inputs,
<span class='lineno'>1113</span>         memory_sequence_length=tiled_sequence_length)
<span class='lineno'>1114</span>     attention_cell = AttentionWrapper(cell, attention_mechanism, ...)
<span class='lineno'>1115</span>     decoder_initial_state = attention_cell.zero_state(
<span class='lineno'>1116</span>         dtype, batch_size=true_batch_size * beam_width)
<span class='lineno'>1117</span>     decoder_initial_state = decoder_initial_state.clone(
<span class='lineno'>1118</span>         cell_state=tiled_encoder_final_state)
<span class='lineno'>1119</span>     ```
<span class='lineno'>1120</span> 
<span class='lineno'>1121</span>     Args:
<span class='lineno'>1122</span>       cell: An instance of `RNNCell`.
<span class='lineno'>1123</span>       attention_mechanism: A list of `AttentionMechanism` instances or a single
<span class='lineno'>1124</span>         instance.
<span class='lineno'>1125</span>       attention_layer_size: A list of Python integers or a single Python
<span class='lineno'>1126</span>         integer, the depth of the attention (output) layer(s). If None
<span class='lineno'>1127</span>         (default), use the context as attention at each time step. Otherwise,
<span class='lineno'>1128</span>         feed the context and cell output into the attention layer to generate
<span class='lineno'>1129</span>         attention at each time step. If attention_mechanism is a list,
<span class='lineno'>1130</span>         attention_layer_size must be a list of the same length. If
<span class='lineno'>1131</span>         attention_layer is set, this must be None.
<span class='lineno'>1132</span>       alignment_history: Python boolean, whether to store alignment history
<span class='lineno'>1133</span>         from all time steps in the final output state (currently stored as a
<span class='lineno'>1134</span>         time major `TensorArray` on which you must call `stack()`).
<span class='lineno'>1135</span>       cell_input_fn: (optional) A `callable`.  The default is:
<span class='lineno'>1136</span>         `lambda inputs, attention: array_ops.concat([inputs, attention], -1)`.
<span class='lineno'>1137</span>       output_attention: Python bool.  If `True` (default), the output at each
<span class='lineno'>1138</span>         time step is the attention value.  This is the behavior of Luong-style
<span class='lineno'>1139</span>         attention mechanisms.  If `False`, the output at each time step is
<span class='lineno'>1140</span>         the output of `cell`.  This is the behavior of Bhadanau-style
<span class='lineno'>1141</span>         attention mechanisms.  In both cases, the `attention` tensor is
<span class='lineno'>1142</span>         propagated to the next time step via the state and is used there.
<span class='lineno'>1143</span>         This flag only controls whether the attention mechanism is propagated
<span class='lineno'>1144</span>         up to the next cell in an RNN stack or to the top RNN output.
<span class='lineno'>1145</span>       initial_cell_state: The initial state value to use for the cell when
<span class='lineno'>1146</span>         the user calls `zero_state()`.  Note that if this value is provided
<span class='lineno'>1147</span>         now, and the user uses a `batch_size` argument of `zero_state` which
<span class='lineno'>1148</span>         does not match the batch size of `initial_cell_state`, proper
<span class='lineno'>1149</span>         behavior is not guaranteed.
<span class='lineno'>1150</span>       name: Name to use when creating ops.
<span class='lineno'>1151</span>       attention_layer: A list of `tf.layers.Layer` instances or a
<span class='lineno'>1152</span>         single `tf.layers.Layer` instance taking the context and cell output as
<span class='lineno'>1153</span>         inputs to generate attention at each time step. If None (default), use
<span class='lineno'>1154</span>         the context as attention at each time step. If attention_mechanism is a
<span class='lineno'>1155</span>         list, attention_layer must be a list of the same length. If
<span class='lineno'>1156</span>         attention_layers_size is set, this must be None.
<span class='lineno'>1157</span> 
<span class='lineno'>1158</span>     Raises:
<span class='lineno'>1159</span>       TypeError: `attention_layer_size` is not None and (`attention_mechanism`
<span class='lineno'>1160</span>         is a list but `attention_layer_size` is not; or vice versa).
<span class='lineno'>1161</span>       ValueError: if `attention_layer_size` is not None, `attention_mechanism`
<span class='lineno'>1162</span>         is a list, and its length does not match that of `attention_layer_size`;
<span class='lineno'>1163</span>         if `attention_layer_size` and `attention_layer` are set simultaneously.
<span class='lineno'>1164</span>     &quot;&quot;&quot;
<span class='lineno'>1165</span>     super(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper', title='<AttentionWrapper>'>AttentionWrapper</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>).__init__(name=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.name', title='None'>name</a>)
<span class='lineno'>1166</span>     <a href='../../../../python/ops/rnn_cell_impl.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl', title='rnn_cell_impl'>rnn_cell_impl</a>.<a href='../../../../python/ops/rnn_cell_impl.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl.assert_like_rnncell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.rnn_cell_impl.assert_like_rnncell', title='(str, CrfDecodeForwardRnnCell) -> ? / (str, MultiRNNCell) -> None / (str, CrfForwardRnnCell) -> None / (str, {DropoutWrapper | MultiRNNCell}) -> None / (str, _RNNCellForTest) -> None / (str, ?) -> None / (str, EmbeddingWrapper) -> None / (str, OutputProjectionWrapper) -> None / (?, ?) -> None / (str, None) -> None'>assert_like_rnncell</a>(&quot;cell&quot;, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell', title='?'>cell</a>)
<span class='lineno'>1167</span>     if isinstance(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='(? -> list, ? -> tuple)'>attention_mechanism</a></a>, (list, tuple)):
<span class='lineno'>1168</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._is_multi', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._is_multi', title='bool'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._is_multi', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._is_multi', title='bool'>_is_multi</a></a> = True
<span class='lineno'>1169</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', title='(? -> list, ? -> tuple)'>attention_mechanisms</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='(? -> list, ? -> tuple)'>attention_mechanism</a>
<span class='lineno'>1170</span>       for <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='? -> list'>attention_mechanism</a> in <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', title='(? -> list, ? -> tuple)'>attention_mechanisms</a>:
<span class='lineno'>1171</span>         if not isinstance(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='? -> list'>attention_mechanism</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism', title='<AttentionMechanism>'>AttentionMechanism</a>):
<span class='lineno'>1172</span>           raise TypeError(
<span class='lineno'>1173</span>               &quot;attention_mechanism must contain only instances of &quot;
<span class='lineno'>1174</span>               &quot;AttentionMechanism, saw type: %s&quot;
<span class='lineno'>1175</span>               % type(attention_mechanism).__name__)
<span class='lineno'>1176</span>     else:
<span class='lineno'>1177</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._is_multi', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._is_multi', title='bool'>_is_multi</a> = False
<span class='lineno'>1178</span>       if not isinstance(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='?'>attention_mechanism</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionMechanism', title='<AttentionMechanism>'>AttentionMechanism</a>):
<span class='lineno'>1179</span>         raise TypeError(
<span class='lineno'>1180</span>             &quot;attention_mechanism must be an AttentionMechanism or list of &quot;
<span class='lineno'>1181</span>             &quot;multiple AttentionMechanism instances, saw type: %s&quot;
<span class='lineno'>1182</span>             % type(attention_mechanism).__name__)
<span class='lineno'>1183</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', title='?'>attention_mechanisms</a> = (<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='?'>attention_mechanism</a>,)
<span class='lineno'>1184</span> 
<span class='lineno'>1185</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell_input_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell_input_fn', title='None'>cell_input_fn</a> is None:
<span class='lineno'>1186</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell_input_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell_input_fn', title='(AttentionWrapper, ?) -> ?'>cell_input_fn</a> = (
<span class='lineno'>1187</span>           lambda <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%658.inputs', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%658.inputs', title='AttentionWrapper'>inputs</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%658.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%658.attention', title='?'>attention</a>: <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.concat', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.concat', title='((?, [?]), int, str) -> ? / ([[?]], int, str) -> None / ([?], int, str) -> None / ([{None | [int]}], int, str) -> None / ([IndexedSlices -> None], int, str) -> None / ([None], int, str) -> None / (?, int, str) -> None / ((None, None), int, str) -> None / ([{IndexedSlices | SparseTensor}], int, str) -> None'>concat</a>([<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%658.inputs', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%658.inputs', title='AttentionWrapper'>inputs</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%658.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%658.attention', title='?'>attention</a>], -1))
<span class='lineno'>1188</span>     else:
<span class='lineno'>1189</span>       if not callable(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell_input_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell_input_fn', title='None'>cell_input_fn</a>):
<span class='lineno'>1190</span>         raise TypeError(
<span class='lineno'>1191</span>             &quot;cell_input_fn must be callable, saw type: %s&quot;
<span class='lineno'>1192</span>             % type(cell_input_fn).__name__)
<span class='lineno'>1193</span> 
<span class='lineno'>1194</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', title='None'>attention_layer_size</a> is not None and <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', title='None'>attention_layer</a> is not None:
<span class='lineno'>1195</span>       raise ValueError(&quot;Only one of attention_layer_size and attention_layer &quot;
<span class='lineno'>1196</span>                        &quot;should be set&quot;)
<span class='lineno'>1197</span> 
<span class='lineno'>1198</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', title='None'>attention_layer_size</a> is not None:
<span class='lineno'>1199</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_sizes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_sizes', title='tuple'>attention_layer_sizes</a> = tuple(
<span class='lineno'>1200</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', title='None'>attention_layer_size</a>
<span class='lineno'>1201</span>           if isinstance(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', title='None'>attention_layer_size</a>, (list, tuple))
<span class='lineno'>1202</span>           else (<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', title='None'>attention_layer_size</a>,))
<span class='lineno'>1203</span>       if len(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_sizes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_sizes', title='tuple'>attention_layer_sizes</a>) != len(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>attention_mechanisms</a>):
<span class='lineno'>1204</span>         raise ValueError(
<span class='lineno'>1205</span>             &quot;If provided, attention_layer_size must contain exactly one &quot;
<span class='lineno'>1206</span>             &quot;integer per attention_mechanism, saw: %d vs %d&quot;
<span class='lineno'>1207</span>             % (len(attention_layer_sizes), len(attention_mechanisms)))
<span class='lineno'>1208</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', title='tuple'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', title='tuple'>_attention_layers</a></a> = tuple(
<span class='lineno'>1209</span>           <a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core', title='core'>layers_core</a>.<a href='../../../../python/layers/core.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.layers.core.Dense', title='<Dense>'>Dense</a>(
<span class='lineno'>1210</span>               <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', title='?'>attention_layer_size</a>,
<span class='lineno'>1211</span>               name=&quot;attention_layer&quot;,
<span class='lineno'>1212</span>               use_bias=False,
<span class='lineno'>1213</span>               dtype=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>attention_mechanisms</a>[<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.i', title='?'>i</a>].dtype)
<span class='lineno'>1214</span>           for <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.i', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.i', title='?'>i</a></a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_size', title='?'>attention_layer_size</a></a> in enumerate(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_sizes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_sizes', title='tuple'>attention_layer_sizes</a>))
<span class='lineno'>1215</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', title='int'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', title='int'>_attention_layer_size</a></a> = sum(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_sizes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer_sizes', title='tuple'>attention_layer_sizes</a>)
<span class='lineno'>1216</span>     elif <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', title='None'>attention_layer</a> is not None:
<span class='lineno'>1217</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', title='tuple'>_attention_layers</a> = tuple(
<span class='lineno'>1218</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', title='None'>attention_layer</a>
<span class='lineno'>1219</span>           if isinstance(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', title='None'>attention_layer</a>, (list, tuple))
<span class='lineno'>1220</span>           else (<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_layer', title='None'>attention_layer</a>,))
<span class='lineno'>1221</span>       if len(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', title='tuple'>_attention_layers</a>) != len(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>attention_mechanisms</a>):
<span class='lineno'>1222</span>         raise ValueError(
<span class='lineno'>1223</span>             &quot;If provided, attention_layer must contain exactly one &quot;
<span class='lineno'>1224</span>             &quot;layer per attention_mechanism, saw: %d vs %d&quot;
<span class='lineno'>1225</span>             % (len(self._attention_layers), len(attention_mechanisms)))
<span class='lineno'>1226</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', title='int'>_attention_layer_size</a> = sum(
<span class='lineno'>1227</span>           layer.compute_output_shape(
<span class='lineno'>1228</span>               [None,
<span class='lineno'>1229</span>                <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell', title='?'>cell</a>.output_size + mechanism.values.shape[-1].value])[-1].value
<span class='lineno'>1230</span>           for layer, mechanism in zip(
<span class='lineno'>1231</span>               <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', title='tuple'>_attention_layers</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>attention_mechanisms</a>))
<span class='lineno'>1232</span>     else:
<span class='lineno'>1233</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', title='tuple'>_attention_layers</a> = None
<span class='lineno'>1234</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', title='int'>_attention_layer_size</a> = sum(
<span class='lineno'>1235</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='?'>attention_mechanism</a>.values.get_shape()[-1].value
<span class='lineno'>1236</span>           for <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='?'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanism', title='?'>attention_mechanism</a></a> in <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>attention_mechanisms</a>)
<span class='lineno'>1237</span> 
<span class='lineno'>1238</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', title='?'>_cell</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell', title='?'>cell</a>
<span class='lineno'>1239</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>_attention_mechanisms</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>attention_mechanisms</a>
<span class='lineno'>1240</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell_input_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell_input_fn', title='(AttentionWrapper, ?) -> ?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell_input_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell_input_fn', title='(AttentionWrapper, ?) -> ?'>_cell_input_fn</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell_input_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.cell_input_fn', title='(AttentionWrapper, ?) -> ?'>cell_input_fn</a>
<span class='lineno'>1241</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._output_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._output_attention', title='bool'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._output_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._output_attention', title='bool'>_output_attention</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.output_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.output_attention', title='bool'>output_attention</a>
<span class='lineno'>1242</span>     <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._alignment_history', title='bool'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._alignment_history', title='bool'>_alignment_history</a></a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.alignment_history', title='bool'>alignment_history</a>
<span class='lineno'>1243</span>     with <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.name_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.name_scope', title='{(None, str, list) -> ? / (None, str, (?, ?, float)) -> {name_scope | variable_scope} / (None, str, [bool]) -> {name_scope | variable_scope} / (None, str, (?, ?, None)) -> {name_scope | variable_scope} / (None, str, [None]) -> {name_scope | variable_scope} / (None, str, [?]) -> {name_scope | variable_scope} / (str, None, None) -> {name_scope | variable_scope} / (None, str, ?) -> {name_scope | variable_scope} / (None, str, [{IndexedSlices | None | SparseTensor}]) -> {name_scope | variable_scope} | <name_scope>}'>name_scope</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.name', title='None'>name</a>, &quot;AttentionWrapperInit&quot;):
<span class='lineno'>1244</span>       if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.initial_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.initial_cell_state', title='None'>initial_cell_state</a> is None:
<span class='lineno'>1245</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._initial_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._initial_cell_state', title='None'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._initial_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._initial_cell_state', title='None'>_initial_cell_state</a></a> = None
<span class='lineno'>1246</span>       else:
<span class='lineno'>1247</span>         <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.final_state_tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.final_state_tensor', title='?'>final_state_tensor</a> = <a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>.<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.flatten', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.flatten', title='{? -> list | EagerIterator | Iterator | None | [?] | [None] | [None] | dict} -> ? / {(? -> list, ? -> tuple) | ? -> list | EagerIterator | Iterator | dict} -> None / {? -> list | dict} -> None / [?] -> None / {IndexedSlices | SparseTensor | [{IndexedSlices | SparseTensor | list}] | list} -> None / ? -> None / None -> None / {(? -> list, ? -> tuple) | EagerIterator | Iterator | dict} -> None / [tuple] -> None'>flatten</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.initial_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.initial_cell_state', title='None'>initial_cell_state</a>)[-1]
<span class='lineno'>1248</span>         <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.state_batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.state_batch_size', title='?'>state_batch_size</a> = (
<span class='lineno'>1249</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.final_state_tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.final_state_tensor', title='?'>final_state_tensor</a>.shape[0].value
<span class='lineno'>1250</span>             or <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.final_state_tensor', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.final_state_tensor', title='?'>final_state_tensor</a>)[0])
<span class='lineno'>1251</span>         <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.error_message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.error_message', title='str'>error_message</a> = (
<span class='lineno'>1252</span>             &quot;When constructing AttentionWrapper %s: &quot; % <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>._base_name +
<span class='lineno'>1253</span>             &quot;Non-matching batch sizes between the memory &quot;
<span class='lineno'>1254</span>             &quot;(encoder output) and initial_cell_state.  Are you using &quot;
<span class='lineno'>1255</span>             &quot;the BeamSearchDecoder?  You may need to tile your initial state &quot;
<span class='lineno'>1256</span>             &quot;via the tf.contrib.seq2seq.tile_batch function with argument &quot;
<span class='lineno'>1257</span>             &quot;multiple=beam_width.&quot;)
<span class='lineno'>1258</span>         with <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.control_dependencies', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.control_dependencies', title='? -> ? / {[?] | [None]} -> _NullContextmanager / None -> _NullContextmanager / list -> _NullContextmanager / [Operation] -> _NullContextmanager / [None] -> _NullContextmanager / ? -> _NullContextmanager / [?] -> _NullContextmanager / [{IndexedSlices -> None | SparseTensor -> None}] -> _NullContextmanager'>control_dependencies</a>(
<span class='lineno'>1259</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks', title='(AttentionWrapper, ?, ?) -> [None] / (AttentionWrapper, ?, str) -> [None]'>_batch_size_checks</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.state_batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.state_batch_size', title='?'>state_batch_size</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.error_message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.error_message', title='str'>error_message</a>)):
<span class='lineno'>1260</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._initial_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._initial_cell_state', title='None'>_initial_cell_state</a> = <a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>.<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', title='? -> ? -> ? / ? -> ? -> None / ? -> TensorArray -> None / ? -> None / list -> list -> None / ? -> _DotString -> _DotString / (_TensorLike, None) -> ? / (IndexedSlices -> None, None) -> None / (None, None) -> None / ({IndexedSlices | SparseTensor}, None) -> None / (?, None) -> None / ({None | [None]}, None) -> None / ({? -> bool | None}, None) -> None / (Tensor, None) -> None -> None / (CondContext, ?) -> {IndexedSlices | SparseTensor | list} -> {IndexedSlices | SparseTensor | list} / ? -> TensorArray -> None -> TensorArray -> None'>map_structure</a>(
<span class='lineno'>1261</span>               lambda <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%659.s', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%659.s', title='?'>s</a>: <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.identity', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.identity', title='(_TensorLike, None) -> ? / (IndexedSlices -> None, None) -> None / (None, None) -> None / ({IndexedSlices | SparseTensor}, None) -> None / (?, None) -> None / ({None | [None]}, None) -> None / ({? -> bool | None}, None) -> None / (Tensor, None) -> None'>identity</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%659.s', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.lambda%659.s', title='?'>s</a>, name=&quot;check_initial_cell_state&quot;),
<span class='lineno'>1262</span>               <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.initial_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.__init__.initial_cell_state', title='None'>initial_cell_state</a>)
<span class='lineno'>1263</span> 
<span class='lineno'>1264</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks', title='(AttentionWrapper, ?, ?) -> [None] / (AttentionWrapper, ?, str) -> [None]'>_batch_size_checks</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.self', title='AttentionWrapper'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.batch_size', title='?'>batch_size</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.error_message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.error_message', title='str'>error_message</a>):
<span class='lineno'>1265</span>     return [<a href='../../../../python/ops/check_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops', title='check_ops'>check_ops</a>.<a href='../../../../python/ops/check_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops.assert_equal', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.check_ops.assert_equal', title='({IndexedSlices | SparseTensor}, float, None, None, None, None) -> ? / (int, ?, None, None, None, None) -> None / (?, int, None, None, None, None) -> None / (?, bool, None, None, None, None) -> None / (None, bool, None, None, None, None) -> None / (None, ?, None, None, None, None) -> None / (?, ?, None, None, None, None) -> None / (?, None, None, None, None, None) -> None / (None, None, None, None, None, None) -> None'>assert_equal</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.batch_size', title='?'>batch_size</a>,
<span class='lineno'>1266</span>                                    <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.attention_mechanism', title='?'>attention_mechanism</a>.batch_size,
<span class='lineno'>1267</span>                                    message=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.error_message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.error_message', title='str'>error_message</a>)
<span class='lineno'>1268</span>             for <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.attention_mechanism', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.attention_mechanism', title='?'>attention_mechanism</a></a> in <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>_attention_mechanisms</a>]
<span class='lineno'>1269</span> 
<span class='lineno'>1270</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', title='(AttentionWrapper, ?) -> tuple / (AttentionWrapper, [()]) -> tuple / (AttentionWrapper, [?]) -> tuple / (AttentionWrapper, [{() | TensorArray}]) -> tuple'>_item_or_tuple</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.self', title='AttentionWrapper'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.seq', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.seq', title='{[()] | [?] | [{() | TensorArray}]}'>seq</a>):
<span class='lineno'>1271</span>     &quot;&quot;&quot;Returns `seq` as tuple or the singular element.
<span class='lineno'>1272</span> 
<span class='lineno'>1273</span>     Which is returned is determined by how the AttentionMechanism(s) were passed
<span class='lineno'>1274</span>     to the constructor.
<span class='lineno'>1275</span> 
<span class='lineno'>1276</span>     Args:
<span class='lineno'>1277</span>       seq: A non-empty sequence of items or generator.
<span class='lineno'>1278</span> 
<span class='lineno'>1279</span>     Returns:
<span class='lineno'>1280</span>        Either the values in the sequence as a tuple if AttentionMechanism(s)
<span class='lineno'>1281</span>        were passed to the constructor as a sequence or the singular element.
<span class='lineno'>1282</span>     &quot;&quot;&quot;
<span class='lineno'>1283</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.t', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.t', title='tuple'>t</a> = tuple(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.seq', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.seq', title='{[()] | [?] | [{() | TensorArray}]}'>seq</a>)
<span class='lineno'>1284</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._is_multi', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._is_multi', title='bool'>_is_multi</a>:
<span class='lineno'>1285</span>       return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.t', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.t', title='tuple'>t</a>
<span class='lineno'>1286</span>     else:
<span class='lineno'>1287</span>       return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.t', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple.t', title='tuple'>t</a>[0]
<span class='lineno'>1288</span> 
<span class='lineno'>1289</span>   @property
<span class='lineno'>1290</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size', title='AttentionWrapper -> int'>output_size</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size.self', title='AttentionWrapper'>self</a>):
<span class='lineno'>1291</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._output_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._output_attention', title='bool'>_output_attention</a>:
<span class='lineno'>1292</span>       return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', title='int'>_attention_layer_size</a>
<span class='lineno'>1293</span>     else:
<span class='lineno'>1294</span>       return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.output_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', title='?'>_cell</a>.output_size
<span class='lineno'>1295</span> 
<span class='lineno'>1296</span>   @property
<span class='lineno'>1297</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size', title='AttentionWrapper -> AttentionWrapperState'>state_size</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', title='AttentionWrapper'>self</a>):
<span class='lineno'>1298</span>     &quot;&quot;&quot;The `state_size` property of `AttentionWrapper`.
<span class='lineno'>1299</span> 
<span class='lineno'>1300</span>     Returns:
<span class='lineno'>1301</span>       An `AttentionWrapperState` tuple containing shapes used by this object.
<span class='lineno'>1302</span>     &quot;&quot;&quot;
<span class='lineno'>1303</span>     return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', title='<AttentionWrapperState>'>AttentionWrapperState</a>(
<span class='lineno'>1304</span>         cell_state=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', title='?'>_cell</a>.state_size,
<span class='lineno'>1305</span>         time=<a href='../../../../python/framework/tensor_shape.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.tensor_shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.tensor_shape', title='tensor_shape'>tensor_shape</a>.<a href='../../../../python/framework/tensor_shape.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.tensor_shape.TensorShape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.tensor_shape.TensorShape', title='<TensorShape>'>TensorShape</a>([]),
<span class='lineno'>1306</span>         attention=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', title='int'>_attention_layer_size</a>,
<span class='lineno'>1307</span>         alignments=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', title='(AttentionWrapper, ?) -> tuple / (AttentionWrapper, [()]) -> tuple / (AttentionWrapper, [?]) -> tuple / (AttentionWrapper, [{() | TensorArray}]) -> tuple'>_item_or_tuple</a>(
<span class='lineno'>1308</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', title='?'>a</a>.alignments_size for <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', title='?'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', title='?'>a</a></a> in <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>_attention_mechanisms</a>),
<span class='lineno'>1309</span>         attention_state=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', title='(AttentionWrapper, ?) -> tuple / (AttentionWrapper, [()]) -> tuple / (AttentionWrapper, [?]) -> tuple / (AttentionWrapper, [{() | TensorArray}]) -> tuple'>_item_or_tuple</a>(
<span class='lineno'>1310</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', title='?'>a</a>.state_size for <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', title='?'>a</a></a> in <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>_attention_mechanisms</a>),
<span class='lineno'>1311</span>         alignment_history=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', title='(AttentionWrapper, ?) -> tuple / (AttentionWrapper, [()]) -> tuple / (AttentionWrapper, [?]) -> tuple / (AttentionWrapper, [{() | TensorArray}]) -> tuple'>_item_or_tuple</a>(
<span class='lineno'>1312</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', title='?'>a</a>.alignments_size if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._alignment_history', title='bool'>_alignment_history</a> else ()
<span class='lineno'>1313</span>             for <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', title='?'><a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.a', title='?'>a</a></a> in <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.state_size.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>_attention_mechanisms</a>))  # sometimes a TensorArray
<span class='lineno'>1314</span> 
<span class='lineno'>1315</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state', title='(AttentionWrapper, ?, ?) -> AttentionWrapperState'>zero_state</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', title='?'>batch_size</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', title='?'>dtype</a>):
<span class='lineno'>1316</span>     &quot;&quot;&quot;Return an initial (zero) state tuple for this `AttentionWrapper`.
<span class='lineno'>1317</span> 
<span class='lineno'>1318</span>     **NOTE** Please see the initializer documentation for details of how
<span class='lineno'>1319</span>     to call `zero_state` if using an `AttentionWrapper` with a
<span class='lineno'>1320</span>     `BeamSearchDecoder`.
<span class='lineno'>1321</span> 
<span class='lineno'>1322</span>     Args:
<span class='lineno'>1323</span>       batch_size: `0D` integer tensor: the batch size.
<span class='lineno'>1324</span>       dtype: The internal state data type.
<span class='lineno'>1325</span> 
<span class='lineno'>1326</span>     Returns:
<span class='lineno'>1327</span>       An `AttentionWrapperState` tuple containing zeroed out tensors and,
<span class='lineno'>1328</span>       possibly, empty `TensorArray` objects.
<span class='lineno'>1329</span> 
<span class='lineno'>1330</span>     Raises:
<span class='lineno'>1331</span>       ValueError: (or, possibly at runtime, InvalidArgument), if
<span class='lineno'>1332</span>         `batch_size` does not match the output size of the encoder passed
<span class='lineno'>1333</span>         to the wrapper object at initialization time.
<span class='lineno'>1334</span>     &quot;&quot;&quot;
<span class='lineno'>1335</span>     with <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.name_scope', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.name_scope', title='{(None, str, list) -> ? / (None, str, (?, ?, float)) -> {name_scope | variable_scope} / (None, str, [bool]) -> {name_scope | variable_scope} / (None, str, (?, ?, None)) -> {name_scope | variable_scope} / (None, str, [None]) -> {name_scope | variable_scope} / (None, str, [?]) -> {name_scope | variable_scope} / (str, None, None) -> {name_scope | variable_scope} / (None, str, ?) -> {name_scope | variable_scope} / (None, str, [{IndexedSlices | None | SparseTensor}]) -> {name_scope | variable_scope} | <name_scope>}'>name_scope</a>(type(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>).__name__ + &quot;ZeroState&quot;, values=[<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', title='?'>batch_size</a>]):
<span class='lineno'>1336</span>       if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._initial_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._initial_cell_state', title='None'>_initial_cell_state</a> is not None:
<span class='lineno'>1337</span>         <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.cell_state', title='None'>cell_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._initial_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._initial_cell_state', title='None'>_initial_cell_state</a>
<span class='lineno'>1338</span>       else:
<span class='lineno'>1339</span>         <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.cell_state', title='?'>cell_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', title='?'>_cell</a>.zero_state(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', title='?'>batch_size</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', title='?'>dtype</a>)
<span class='lineno'>1340</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.error_message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.error_message', title='str'>error_message</a> = (
<span class='lineno'>1341</span>           &quot;When calling zero_state of AttentionWrapper %s: &quot; % <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>._base_name +
<span class='lineno'>1342</span>           &quot;Non-matching batch sizes between the memory &quot;
<span class='lineno'>1343</span>           &quot;(encoder output) and the requested batch size.  Are you using &quot;
<span class='lineno'>1344</span>           &quot;the BeamSearchDecoder?  If so, make sure your encoder output has &quot;
<span class='lineno'>1345</span>           &quot;been tiled to beam_width via tf.contrib.seq2seq.tile_batch, and &quot;
<span class='lineno'>1346</span>           &quot;the batch_size= argument passed to zero_state is &quot;
<span class='lineno'>1347</span>           &quot;batch_size * beam_width.&quot;)
<span class='lineno'>1348</span>       with <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.control_dependencies', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.control_dependencies', title='? -> ? / {[?] | [None]} -> _NullContextmanager / None -> _NullContextmanager / list -> _NullContextmanager / [Operation] -> _NullContextmanager / [None] -> _NullContextmanager / ? -> _NullContextmanager / [?] -> _NullContextmanager / [{IndexedSlices -> None | SparseTensor -> None}] -> _NullContextmanager'>control_dependencies</a>(
<span class='lineno'>1349</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks', title='(AttentionWrapper, ?, ?) -> [None] / (AttentionWrapper, ?, str) -> [None]'>_batch_size_checks</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', title='?'>batch_size</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.error_message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.error_message', title='str'>error_message</a>)):
<span class='lineno'>1350</span>         <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.cell_state', title='?'>cell_state</a> = <a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest', title='nest'>nest</a>.<a href='../../../../python/util/nest.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.util.nest.map_structure', title='? -> ? -> ? / ? -> ? -> None / ? -> TensorArray -> None / ? -> None / list -> list -> None / ? -> _DotString -> _DotString / (_TensorLike, None) -> ? / (IndexedSlices -> None, None) -> None / (None, None) -> None / ({IndexedSlices | SparseTensor}, None) -> None / (?, None) -> None / ({None | [None]}, None) -> None / ({? -> bool | None}, None) -> None / (Tensor, None) -> None -> None / (CondContext, ?) -> {IndexedSlices | SparseTensor | list} -> {IndexedSlices | SparseTensor | list} / ? -> TensorArray -> None -> TensorArray -> None'>map_structure</a>(
<span class='lineno'>1351</span>             lambda <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.lambda%660.s', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.lambda%660.s', title='?'>s</a>: <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.identity', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.identity', title='(_TensorLike, None) -> ? / (IndexedSlices -> None, None) -> None / (None, None) -> None / ({IndexedSlices | SparseTensor}, None) -> None / (?, None) -> None / ({None | [None]}, None) -> None / ({? -> bool | None}, None) -> None / (Tensor, None) -> None'>identity</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.lambda%660.s', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.lambda%660.s', title='?'>s</a>, name=&quot;checked_cell_state&quot;),
<span class='lineno'>1352</span>             <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.cell_state', title='None'>cell_state</a>)
<span class='lineno'>1353</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.initial_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.initial_alignments', title='[?]'>initial_alignments</a> = [
<span class='lineno'>1354</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', title='?'>attention_mechanism</a>.initial_alignments(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', title='?'>batch_size</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', title='?'>dtype</a>)
<span class='lineno'>1355</span>           for <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', title='?'>attention_mechanism</a></a> in <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>_attention_mechanisms</a>]
<span class='lineno'>1356</span>       return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', title='<AttentionWrapperState>'>AttentionWrapperState</a>(
<span class='lineno'>1357</span>           cell_state=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.cell_state', title='?'>cell_state</a>,
<span class='lineno'>1358</span>           time=<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.zeros', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.zeros', title='(?, None, None) -> ? / ([?], ?, None) -> ? / ([int], ?, None) -> ? / ([?], DType, None) -> ? / (?, ?, None) -> ? / (?, DType, None) -> ? / (None, DType, None) -> ? / (?, {IndexedSlices -> None | SparseTensor -> None}, None) -> ? / ([None], DType, None) -> ? / (TensorShape, DType, None) -> ?'>zeros</a>([], dtype=<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes', title='dtypes'>dtypes</a>.<a href='../../../../python/framework/dtypes.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.int32', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.dtypes.int32', title='DType'>int32</a>),
<span class='lineno'>1359</span>           attention=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._zero_state_tensors', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._zero_state_tensors', title='(CrfDecodeForwardRnnCell -> ?, None, None) -> ? / (CrfForwardRnnCell -> ?, None, None) -> None / (int, ?, ?) -> None / (_RNNCellForTest -> ?, None, None) -> None / (LSTMCell -> {LSTMStateTuple | int}, int, ?) -> None / (?, ?, ?) -> None / (RNNCell -> None, None, None) -> None / (RNNCell -> None, ?, ?) -> None'>_zero_state_tensors</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layer_size', title='int'>_attention_layer_size</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', title='?'>batch_size</a>,
<span class='lineno'>1360</span>                                         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', title='?'>dtype</a>),
<span class='lineno'>1361</span>           alignments=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', title='(AttentionWrapper, ?) -> tuple / (AttentionWrapper, [()]) -> tuple / (AttentionWrapper, [?]) -> tuple / (AttentionWrapper, [{() | TensorArray}]) -> tuple'>_item_or_tuple</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.initial_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.initial_alignments', title='[?]'>initial_alignments</a>),
<span class='lineno'>1362</span>           attention_state=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', title='(AttentionWrapper, ?) -> tuple / (AttentionWrapper, [()]) -> tuple / (AttentionWrapper, [?]) -> tuple / (AttentionWrapper, [{() | TensorArray}]) -> tuple'>_item_or_tuple</a>(
<span class='lineno'>1363</span>               <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', title='?'>attention_mechanism</a>.initial_state(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.batch_size', title='?'>batch_size</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', title='?'>dtype</a>)
<span class='lineno'>1364</span>               for <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.attention_mechanism', title='?'>attention_mechanism</a></a> in <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>_attention_mechanisms</a>),
<span class='lineno'>1365</span>           alignment_history=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', title='(AttentionWrapper, ?) -> tuple / (AttentionWrapper, [()]) -> tuple / (AttentionWrapper, [?]) -> tuple / (AttentionWrapper, [{() | TensorArray}]) -> tuple'>_item_or_tuple</a>(
<span class='lineno'>1366</span>               <a href='../../../../python/ops/tensor_array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.tensor_array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.tensor_array_ops', title='tensor_array_ops'>tensor_array_ops</a>.<a href='../../../../python/ops/tensor_array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.tensor_array_ops.TensorArray', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.tensor_array_ops.TensorArray', title='<TensorArray>'>TensorArray</a>(
<span class='lineno'>1367</span>                   <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.dtype', title='?'>dtype</a>,
<span class='lineno'>1368</span>                   size=0,
<span class='lineno'>1369</span>                   dynamic_size=True,
<span class='lineno'>1370</span>                   element_shape=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.alignment', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.alignment', title='?'>alignment</a>.shape)
<span class='lineno'>1371</span>               if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._alignment_history', title='bool'>_alignment_history</a> else ()
<span class='lineno'>1372</span>               for <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.alignment', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.alignment', title='?'><a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.alignment', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.alignment', title='?'>alignment</a></a> in <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.initial_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.zero_state.initial_alignments', title='[?]'>initial_alignments</a>))
<span class='lineno'>1373</span> 
<span class='lineno'>1374</span>   def <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call', title='(AttentionWrapper, ?, ?) -> (None, AttentionWrapperState)'>call</a>(<a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.inputs', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.inputs', title='?'>inputs</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', title='?'>state</a>):
<span class='lineno'>1375</span>     &quot;&quot;&quot;Perform a step of attention-wrapped RNN.
<span class='lineno'>1376</span> 
<span class='lineno'>1377</span>     - Step 1: Mix the `inputs` and previous step&#39;s `attention` output via
<span class='lineno'>1378</span>       `cell_input_fn`.
<span class='lineno'>1379</span>     - Step 2: Call the wrapped `cell` with this input and its previous state.
<span class='lineno'>1380</span>     - Step 3: Score the cell&#39;s output with `attention_mechanism`.
<span class='lineno'>1381</span>     - Step 4: Calculate the alignments by passing the score through the
<span class='lineno'>1382</span>       `normalizer`.
<span class='lineno'>1383</span>     - Step 5: Calculate the context vector as the inner product between the
<span class='lineno'>1384</span>       alignments and the attention_mechanism&#39;s values (memory).
<span class='lineno'>1385</span>     - Step 6: Calculate the attention output by concatenating the cell output
<span class='lineno'>1386</span>       and context through the attention layer (a linear layer with
<span class='lineno'>1387</span>       `attention_layer_size` outputs).
<span class='lineno'>1388</span> 
<span class='lineno'>1389</span>     Args:
<span class='lineno'>1390</span>       inputs: (Possibly nested tuple of) Tensor, the input at this time step.
<span class='lineno'>1391</span>       state: An instance of `AttentionWrapperState` containing
<span class='lineno'>1392</span>         tensors from the previous time step.
<span class='lineno'>1393</span> 
<span class='lineno'>1394</span>     Returns:
<span class='lineno'>1395</span>       A tuple `(attention_or_cell_output, next_state)`, where:
<span class='lineno'>1396</span> 
<span class='lineno'>1397</span>       - `attention_or_cell_output` depending on `output_attention`.
<span class='lineno'>1398</span>       - `next_state` is an instance of `AttentionWrapperState`
<span class='lineno'>1399</span>          containing the state calculated at this time step.
<span class='lineno'>1400</span> 
<span class='lineno'>1401</span>     Raises:
<span class='lineno'>1402</span>       TypeError: If `state` is not an instance of `AttentionWrapperState`.
<span class='lineno'>1403</span>     &quot;&quot;&quot;
<span class='lineno'>1404</span>     if not isinstance(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', title='?'>state</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', title='<AttentionWrapperState>'>AttentionWrapperState</a>):
<span class='lineno'>1405</span>       raise TypeError(&quot;Expected state to be instance of AttentionWrapperState. &quot;
<span class='lineno'>1406</span>                       &quot;Received type %s instead.&quot;  % type(state))
<span class='lineno'>1407</span> 
<span class='lineno'>1408</span>     # Step 1: Calculate the true inputs to the cell based on the
<span class='lineno'>1409</span>     # previous attention value.
<span class='lineno'>1410</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_inputs', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_inputs', title='?'>cell_inputs</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell_input_fn', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell_input_fn', title='(AttentionWrapper, ?) -> ?'>_cell_input_fn</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.inputs', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.inputs', title='?'>inputs</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', title='?'>state</a>.attention)
<span class='lineno'>1411</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_state', title='?'>cell_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', title='?'>state</a>.cell_state
<span class='lineno'>1412</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', title='?'>cell_output</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_cell_state', title='?'>next_cell_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._cell', title='?'>_cell</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_inputs', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_inputs', title='?'>cell_inputs</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_state', title='?'>cell_state</a>)
<span class='lineno'>1413</span> 
<span class='lineno'>1414</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_batch_size', title='?'>cell_batch_size</a> = (
<span class='lineno'>1415</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', title='?'>cell_output</a>.shape[0].value or <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.shape', title='({None | [None] | [{[None] | list}] | list}, None, DType) -> ? / (LinearOperatorLowRankUpdate -> None, None, DType) -> None / ({IndexedSlices | SparseTensor}, None, DType) -> None / ({DeferredTensor | [DeferredTensor] | [None]}, None, DType) -> None / (_TensorLike, None, DType) -> None / ({_TensorLike | list}, None, DType) -> None / (?, None, DType) -> None / (SparseTensor, None, DType) -> None / (None, None, DType) -> None'>shape</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', title='?'>cell_output</a>)[0])
<span class='lineno'>1416</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.error_message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.error_message', title='str'>error_message</a> = (
<span class='lineno'>1417</span>         &quot;When applying AttentionWrapper %s: &quot; % <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='../../../../python/keras/engine/base_layer.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.keras.engine.base_layer.Layer.name', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.keras.engine.base_layer.Layer.name', title='Layer -> str'>name</a> +
<span class='lineno'>1418</span>         &quot;Non-matching batch sizes between the memory &quot;
<span class='lineno'>1419</span>         &quot;(encoder output) and the query (decoder output).  Are you using &quot;
<span class='lineno'>1420</span>         &quot;the BeamSearchDecoder?  You may need to tile your memory input via &quot;
<span class='lineno'>1421</span>         &quot;the tf.contrib.seq2seq.tile_batch function with argument &quot;
<span class='lineno'>1422</span>         &quot;multiple=beam_width.&quot;)
<span class='lineno'>1423</span>     with <a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops', title='ops'>ops</a>.<a href='../../../../python/framework/ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.control_dependencies', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.framework.ops.control_dependencies', title='? -> ? / {[?] | [None]} -> _NullContextmanager / None -> _NullContextmanager / list -> _NullContextmanager / [Operation] -> _NullContextmanager / [None] -> _NullContextmanager / ? -> _NullContextmanager / [?] -> _NullContextmanager / [{IndexedSlices -> None | SparseTensor -> None}] -> _NullContextmanager'>control_dependencies</a>(
<span class='lineno'>1424</span>         <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._batch_size_checks', title='(AttentionWrapper, ?, ?) -> [None] / (AttentionWrapper, ?, str) -> [None]'>_batch_size_checks</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_batch_size', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_batch_size', title='?'>cell_batch_size</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.error_message', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.error_message', title='str'>error_message</a>)):
<span class='lineno'>1425</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', title='None'>cell_output</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.identity', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.identity', title='(_TensorLike, None) -> ? / (IndexedSlices -> None, None) -> None / (None, None) -> None / ({IndexedSlices | SparseTensor}, None) -> None / (?, None) -> None / ({None | [None]}, None) -> None / ({? -> bool | None}, None) -> None / (Tensor, None) -> None'>identity</a>(
<span class='lineno'>1426</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', title='?'>cell_output</a>, name=&quot;checked_cell_output&quot;)
<span class='lineno'>1427</span> 
<span class='lineno'>1428</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._is_multi', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._is_multi', title='bool'>_is_multi</a>:
<span class='lineno'>1429</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_attention_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_attention_state', title='?'>previous_attention_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', title='?'>state</a>.attention_state
<span class='lineno'>1430</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_alignment_history', title='?'>previous_alignment_history</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', title='?'>state</a>.alignment_history
<span class='lineno'>1431</span>     else:
<span class='lineno'>1432</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_attention_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_attention_state', title='[?]'>previous_attention_state</a> = [<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', title='?'>state</a>.attention_state]
<span class='lineno'>1433</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_alignment_history', title='[?]'>previous_alignment_history</a> = [<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', title='?'>state</a>.alignment_history]
<span class='lineno'>1434</span> 
<span class='lineno'>1435</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_alignments', title='[?]'>all_alignments</a> = []
<span class='lineno'>1436</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attentions', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attentions', title='[None]'>all_attentions</a> = []
<span class='lineno'>1437</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attention_states', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attention_states', title='[?]'>all_attention_states</a> = []
<span class='lineno'>1438</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.maybe_all_histories', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.maybe_all_histories', title='[()]'>maybe_all_histories</a> = []
<span class='lineno'>1439</span>     for <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.i', title='?'>i</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention_mechanism', title='?'>attention_mechanism</a> in enumerate(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_mechanisms', title='{(? -> list, ? -> tuple) | ?}'>_attention_mechanisms</a>):
<span class='lineno'>1440</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention', title='None'>attention</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.alignments', title='?'>alignments</a>, <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_attention_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_attention_state', title='?'>next_attention_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper._compute_attention', title='(?, None, list, None) -> (None, ?, ?) / (?, ?, ?, ?) -> (None, ?, ?)'>_compute_attention</a>(
<span class='lineno'>1441</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention_mechanism', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention_mechanism', title='?'>attention_mechanism</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', title='None'>cell_output</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_attention_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_attention_state', title='[?]'>previous_attention_state</a>[<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.i', title='?'>i</a>],
<span class='lineno'>1442</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', title='tuple'>_attention_layers</a>[<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.i', title='?'>i</a>] if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._attention_layers', title='tuple'>_attention_layers</a> else None)
<span class='lineno'>1443</span>       <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.alignment_history', title='()'>alignment_history</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.previous_alignment_history', title='[?]'>previous_alignment_history</a>[<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.i', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.i', title='?'>i</a>].write(
<span class='lineno'>1444</span>           <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', title='?'>state</a>.time, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.alignments', title='?'>alignments</a>) if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._alignment_history', title='bool'>_alignment_history</a> else ()
<span class='lineno'>1445</span> 
<span class='lineno'>1446</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attention_states', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attention_states', title='[?]'>all_attention_states</a>.append(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_attention_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_attention_state', title='?'>next_attention_state</a>)
<span class='lineno'>1447</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_alignments', title='[?]'>all_alignments</a>.append(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.alignments', title='?'>alignments</a>)
<span class='lineno'>1448</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attentions', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attentions', title='[None]'>all_attentions</a>.append(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention', title='None'>attention</a>)
<span class='lineno'>1449</span>       <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.maybe_all_histories', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.maybe_all_histories', title='[()]'>maybe_all_histories</a>.append(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.alignment_history', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.alignment_history', title='()'>alignment_history</a>)
<span class='lineno'>1450</span> 
<span class='lineno'>1451</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention', title='None'>attention</a> = <a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops', title='array_ops'>array_ops</a>.<a href='../../../../python/ops/array_ops.py.html#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.concat', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.python.ops.array_ops.concat', title='((?, [?]), int, str) -> ? / ([[?]], int, str) -> None / ([?], int, str) -> None / ([{None | [int]}], int, str) -> None / ([IndexedSlices -> None], int, str) -> None / ([None], int, str) -> None / (?, int, str) -> None / ((None, None), int, str) -> None / ([{IndexedSlices | SparseTensor}], int, str) -> None'>concat</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attentions', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attentions', title='[None]'>all_attentions</a>, 1)
<span class='lineno'>1452</span>     <a name='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_state', title='AttentionWrapperState'>next_state</a> = <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapperState', title='<AttentionWrapperState>'>AttentionWrapperState</a>(
<span class='lineno'>1453</span>         time=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.state', title='?'>state</a>.time + 1,
<span class='lineno'>1454</span>         cell_state=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_cell_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_cell_state', title='?'>next_cell_state</a>,
<span class='lineno'>1455</span>         attention=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention', title='None'>attention</a>,
<span class='lineno'>1456</span>         attention_state=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', title='(AttentionWrapper, ?) -> tuple / (AttentionWrapper, [()]) -> tuple / (AttentionWrapper, [?]) -> tuple / (AttentionWrapper, [{() | TensorArray}]) -> tuple'>_item_or_tuple</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attention_states', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_attention_states', title='[?]'>all_attention_states</a>),
<span class='lineno'>1457</span>         alignments=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', title='(AttentionWrapper, ?) -> tuple / (AttentionWrapper, [()]) -> tuple / (AttentionWrapper, [?]) -> tuple / (AttentionWrapper, [{() | TensorArray}]) -> tuple'>_item_or_tuple</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_alignments', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.all_alignments', title='[?]'>all_alignments</a>),
<span class='lineno'>1458</span>         alignment_history=<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._item_or_tuple', title='(AttentionWrapper, ?) -> tuple / (AttentionWrapper, [()]) -> tuple / (AttentionWrapper, [?]) -> tuple / (AttentionWrapper, [{() | TensorArray}]) -> tuple'>_item_or_tuple</a>(<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.maybe_all_histories', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.maybe_all_histories', title='[()]'>maybe_all_histories</a>))
<span class='lineno'>1459</span> 
<span class='lineno'>1460</span>     if <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.self', title='AttentionWrapper'>self</a>.<a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._output_attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper._output_attention', title='bool'>_output_attention</a>:
<span class='lineno'>1461</span>       return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.attention', title='None'>attention</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_state', title='AttentionWrapperState'>next_state</a>
<span class='lineno'>1462</span>     else:
<span class='lineno'>1463</span>       return <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.cell_output', title='None'>cell_output</a>, <a href='#.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_state', xid ='.Users.malinda.Documents.RectrofitinMLtoCode.Python.TensorflowEx.tensorflow.contrib.seq2seq.python.ops.attention_wrapper.AttentionWrapper.call.next_state', title='AttentionWrapperState'>next_state</a>
</pre></td></tr></table></body></html>